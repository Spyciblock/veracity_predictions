{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMozYFmna1d5"
      },
      "source": [
        "# Set up Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLKjwLUTQw1Z",
        "outputId": "999aae13-52b3-4a3c-ed9a-6563d118256e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# mounts Google Drive to the Colab VM\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/',force_remount=True)\n",
        "\n",
        "# project github foldername\n",
        "FOLDERNAME = '/content/drive/My Drive/Colab Notebooks/Onclusive_work/fake_flow'\n",
        "# '/content/drive/My Drive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master'\n",
        "\n",
        "\n",
        "# load python files from foldername\n",
        "import sys\n",
        "sys.path.append(FOLDERNAME)\n",
        "\n",
        "# for auto-reloading external modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KmtI-PCkQ_x3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "585f8309-0c08-4e82-f657-3a5acfc2427f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "sys.path.append(os.path.abspath(FOLDERNAME))\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cMp-6_bSQ_30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "724d9930-5350-4bed-8c44-ff7ef78ee95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Onclusive_work\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/Onclusive_work'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# %cd '/content/drive/My Drive/Colab Notebooks/Onclusive_work/fake_flow'\n",
        "% cd '/content/drive/My Drive/Colab Notebooks/Onclusive_work/'\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KI3WKyxqQ_6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b7cdea-59ab-4c8d-d8d5-73821973a6db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Analysis_cs224nProject.ipynb\t\t  Onclusive_ML_Challenge.ipynb\n",
            " checkpoint-154-epoch-1\t\t\t  preds.json\n",
            " checkpoint-308-epoch-2\t\t\t  results.json\n",
            " checkpoint-462-epoch-3\t\t\t  roberta_onnx_outputs\n",
            " checkpoint-616-epoch-4\t\t\t  torch_glove.py\n",
            " checkpoint-770-epoch-5\t\t\t  torch_model_base.py\n",
            "'Copie de Onclusive_ML_Challenge.ipynb'   torch_rnn_classifier.py\n",
            " cs224nProject.ipynb\t\t\t  torch_shallow_neural_classifier.py\n",
            " fake_flow\t\t\t\t  utils.py\n",
            " Fakeflow.ipynb\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fs2_bexRaE8"
      },
      "source": [
        "# Original Fakeflow:\n",
        "\n",
        "To run the model, run the file: `fake_flow.py`\n",
        "\n",
        "1) Place your data in the folder `./data/DATASET_NAME`\n",
        "like `/data/ReCOVery`\n",
        "\n",
        "\n",
        "2) Install GoogleNEws, and put in fake_flow directory then unzip:\n",
        " from\n",
        "- `https://code.google.com/archive/p/word2vec/`\n",
        "\n",
        "- `gzip -d GoogleNews-vectors-negative300.bin.gz` \n",
        "\n",
        "3) Collect and prepare Recovery dataset:\n",
        "Initialize train/test data splits once for Recovery dataset.\n",
        "\n",
        "Parameter: \n",
        "`-d`: dataset name (i.e. ReCOVery).\n",
        "- Run: `python splits.py -d ReCOVery`\n",
        "-----------------------------\n",
        "Parameters:\n",
        "`-d`: dataset name (i.e. ReCOVery, PubHealth ).\n",
        "\n",
        "`-otherd`: second dataset name (i.e.  ReCOVery ).\n",
        "\n",
        "`-sn`: number of segments.\n",
        "\n",
        "`-epochs`: number of epochs (default 50).\n",
        "\n",
        "`-batch_size`: batch_size (default 64).\n",
        "\n",
        "`-s`: to search for params; enter a number larger than 0 to search for N different combination of parameters (e.g. 150).\n",
        "\n",
        "`-m`: mode (train or test); if you want to load a pretrained model.\n",
        "\n",
        "`-c`: mode (True/False by default) to combine 2 datasets in training part and test on PubHealth\n",
        "\n",
        "`-newproc`: mode (True/False by default) to use my custom model\n",
        "\n",
        "\n",
        "You have to change datasets name( -d and -otherd).\n",
        "\n",
        "Some examples:Use only the dataset PubHealth:\n",
        "> python fake_flow.py -d PubHealth -sn 10\n",
        "\n",
        "To load saved model after training=testing:\n",
        "> python fake_flow.py -d PubHealth -sn 10 -m test\n",
        "\n",
        "To search for best params:\n",
        "> python fake_flow.py -d PubHealth -s 80\n",
        "\n",
        "To train with both PubHealth and ReCOVery datasets and test on PubHealth:\n",
        "> python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True\n",
        "\n",
        "To search for best params with training on PubHealth and ReCOVery datasets and test on PubHealth:\n",
        "> python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True -s 60 \n",
        "\n",
        "To use the custom model, use previous examples code, and add \n",
        "`-newproc True`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yLgFwCu8Czs"
      },
      "source": [
        "## Install Wor2vec embeddings then requirements for fakeflow model\n",
        "Use the code cell below or download manually on `https://code.google.com/archive/p/word2vec/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oPoAr9iMSP59"
      },
      "outputs": [],
      "source": [
        "# !wget -P . -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6vqRlza7QorF"
      },
      "outputs": [],
      "source": [
        "#Unzip the directory\n",
        "# !gzip -d GoogleNews-vectors-negative300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## set path\n",
        "% cd '/content/drive/My Drive/Colab Notebooks/Onclusive_work/fake_flow'\n",
        "os.getcwd()"
      ],
      "metadata": {
        "id": "3ythF3LN_vi-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e4f5ccc3-a650-4827-8597-6ea9a1266843"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Onclusive_work/fake_flow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/Colab Notebooks/Onclusive_work/fake_flow'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sGd1r1LD8G_7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bffb5be-69b6-45a1-d9a8-230cad292931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==3.8.0\n",
            "  Downloading gensim-3.8.0-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting joblib==0.14.1\n",
            "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 39.3 MB/s \n",
            "\u001b[?25hCollecting Keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 52.6 MB/s \n",
            "\u001b[?25hCollecting Keras-Preprocessing==1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.1-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 891 kB/s \n",
            "\u001b[?25hCollecting keras-self-attention==0.35.0\n",
            "  Downloading keras-self-attention-0.35.0.tar.gz (11 kB)\n",
            "Collecting numpy==1.16.0\n",
            "  Downloading numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 93 kB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 61.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.20.2\n",
            "  Downloading scikit_learn-0.20.2-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4 MB 2.1 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.32.1\n",
            "  Downloading tqdm-4.32.1-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 209 kB/s \n",
            "\u001b[?25hCollecting hyperopt==0.1.1\n",
            "  Downloading hyperopt-0.1.1-py3-none-any.whl (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 39.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow==2.3.0\n",
            "  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 43 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (3.2.2)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.0->-r requirements.txt (line 1)) (6.0.0)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras==2.2.4->-r requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->-r requirements.txt (line 7)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas==0.24.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.1->-r requirements.txt (line 12)) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.1->-r requirements.txt (line 12)) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.1.1->-r requirements.txt (line 12)) (4.1.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (1.46.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (1.14.1)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (0.37.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (1.1.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (1.6.3)\n",
            "Collecting h5py\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 37.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (1.0.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3.0->-r requirements.txt (line 13)) (2.8.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0->-r requirements.txt (line 13)) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 14)) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 14)) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 14)) (0.11.0)\n",
            "Building wheels for collected packages: keras-self-attention, nltk\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.35.0-py3-none-any.whl size=18996 sha256=726f4105e34502d525e8e82f054be4130de2f7a72503d6c62d0746b72539fe51\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/4a/b9/5fa985d869fcbef3683efb33b6e0263dc20ea97c3a2f949f42\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449921 sha256=181ab008d2f27f709335f123e16bb3e74df45471027996a4a7a4b1c0776c3455\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "Successfully built keras-self-attention nltk\n",
            "Installing collected packages: numpy, h5py, Keras-Preprocessing, keras-applications, tensorflow-estimator, Keras, gast, tqdm, tensorflow, scikit-learn, pandas, nltk, keras-self-attention, joblib, hyperopt, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: Keras-Preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.1.2\n",
            "    Uninstalling Keras-Preprocessing-1.1.2:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.2\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 2.8.0\n",
            "    Uninstalling keras-2.8.0:\n",
            "      Successfully uninstalled keras-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.64.0\n",
            "    Uninstalling tqdm-4.64.0:\n",
            "      Successfully uninstalled tqdm-4.64.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0+zzzcolab20220506162203\n",
            "    Uninstalling tensorflow-2.8.0+zzzcolab20220506162203:\n",
            "      Successfully uninstalled tensorflow-2.8.0+zzzcolab20220506162203\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: hyperopt\n",
            "    Found existing installation: hyperopt 0.1.2\n",
            "    Uninstalling hyperopt-0.1.2:\n",
            "      Successfully uninstalled hyperopt-0.1.2\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "xarray 0.18.2 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.16.0 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.32.1 which is incompatible.\n",
            "scikit-image 0.18.3 requires numpy>=1.16.5, but you have numpy 1.16.0 which is incompatible.\n",
            "pywavelets 1.3.0 requires numpy>=1.17.3, but you have numpy 1.16.0 which is incompatible.\n",
            "pyerfa 2.0.0.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "pyarrow 6.0.1 requires numpy>=1.16.6, but you have numpy 1.16.0 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "panel 0.12.1 requires tqdm>=4.48.0, but you have tqdm 4.32.1 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.16.0 which is incompatible.\n",
            "jaxlib 0.3.7+cuda11.cudnn805 requires numpy>=1.19, but you have numpy 1.16.0 which is incompatible.\n",
            "jax 0.3.8 requires numpy>=1.19, but you have numpy 1.16.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.32.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "astropy 4.3.1 requires numpy>=1.17, but you have numpy 1.16.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Keras-2.2.4 Keras-Preprocessing-1.1.1 gast-0.3.3 gensim-3.8.0 h5py-2.10.0 hyperopt-0.1.1 joblib-0.14.1 keras-applications-1.0.8 keras-self-attention-0.35.0 nltk-3.4.5 numpy-1.16.0 pandas-0.24.2 scikit-learn-0.20.2 tensorflow-2.3.0 tensorflow-estimator-2.3.0 tqdm-4.32.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#intall requirements\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow-gpu==1.14.0"
      ],
      "metadata": {
        "id": "QRYIgP1MGUG9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f856fee-4348-4958-aac1-9f9b1bfe4357"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "RuntimeError: empty_like method already has a different docstring\n",
            "]\n",
            "[autoreload of numpy.core.numerictypes failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'sctypeNA' from 'numpy.core._type_aliases' (/usr/local/lib/python3.7/dist-packages/numpy/core/_type_aliases.py)\n",
            "]\n",
            "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'int_asbuffer' from 'numpy.core.multiarray' (/usr/local/lib/python3.7/dist-packages/numpy/core/multiarray.py)\n",
            "]\n",
            "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'type_check' is not defined\n",
            "]\n",
            "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'defmatrix' is not defined\n",
            "]\n",
            "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.core.numeric' (/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py)\n",
            "]\n",
            "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.core.numeric' (/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py)\n",
            "]\n",
            "[autoreload of numpy.fft failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name '_FFTCache' from 'numpy.fft.helper' (/usr/local/lib/python3.7/dist-packages/numpy/fft/helper.py)\n",
            "]\n",
            "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.core.numeric' (/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py)\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MFj2wYBcjPQY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ae8ee32-aef6-443e-fe75-058c65ece2d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 13 kB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.3.3)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.37.1)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 906 kB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 45.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (2.8.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4) (1.6.3)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.8 MB 31.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4) (3.3.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4) (3.2.0)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68712 sha256=178250eca1cdd331d54a90e571d560d317be926fdeac434be1938428d8d39be3\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, keras-preprocessing, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.16.0\n",
            "    Uninstalling numpy-1.16.0:\n",
            "      Successfully uninstalled numpy-1.16.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.1\n",
            "    Uninstalling grpcio-1.46.1:\n",
            "      Successfully uninstalled grpcio-1.46.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Attempting uninstall: keras-preprocessing\n",
            "    Found existing installation: Keras-Preprocessing 1.1.1\n",
            "    Uninstalling Keras-Preprocessing-1.1.1:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
            "spacy 2.2.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.32.1 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.32.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 flatbuffers-1.12 grpcio-1.32.0 keras-preprocessing-1.1.2 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow==2.4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "tt4ZHzrwLtm6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e20934-efa5-4d73-d3fc-b7185a696b5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of numpy.core.multiarray failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "RuntimeError: empty_like method already has a different docstring\n",
            "]\n",
            "[autoreload of numpy.core.overrides failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "RuntimeError: implement_array_function method already has a different docstring\n",
            "]\n",
            "[autoreload of numpy.core.numeric failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'asarray' from 'numpy.core._asarray' (/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py)\n",
            "]\n",
            "[autoreload of numpy.core.fromnumeric failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'asarray' from 'numpy.core._asarray' (/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py)\n",
            "]\n",
            "[autoreload of numpy.core._methods failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.compat' (/usr/local/lib/python3.7/dist-packages/numpy/compat/__init__.py)\n",
            "]\n",
            "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'type_check' is not defined\n",
            "]\n",
            "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'defmatrix' is not defined\n",
            "]\n",
            "[autoreload of numpy.linalg.linalg failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ValueError: Only callable can be used as callback\n",
            "]\n",
            "[autoreload of numpy.lib.npyio failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.compat' (/usr/local/lib/python3.7/dist-packages/numpy/compat/__init__.py)\n",
            "]\n",
            "[autoreload of numpy.lib.format failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.compat' (/usr/local/lib/python3.7/dist-packages/numpy/compat/__init__.py)\n",
            "]\n",
            "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ImportError: cannot import name 'pickle' from 'numpy.compat' (/usr/local/lib/python3.7/dist-packages/numpy/compat/__init__.py)\n",
            "]\n",
            "[autoreload of numpy.testing failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name '_private' is not defined\n",
            "]\n",
            "[autoreload of numpy.testing._private.utils failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "AttributeError: module 'numpy.linalg' has no attribute 'lapack_lite'\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.32.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.3 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.2.1-py3-none-any.whl (342 kB)\n",
            "\u001b[K     |████████████████████████████████| 342 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.62.1\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 41.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 41.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 42.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (0.24.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 41.1 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 51.0 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.0->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, tqdm, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.32.1\n",
            "    Uninstalling tqdm-4.32.1:\n",
            "      Successfully uninstalled tqdm-4.32.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.2.1 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 tqdm-4.64.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip upgrade Keras-Preprocessing \n",
        "!pip install update Keras-self-attention  "
      ],
      "metadata": {
        "id": "-sr0lcVEzSql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9246eeff-a4f2-4a44-b109-17e829382337"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting update\n",
            "  Downloading update-0.0.1-py2.py3-none-any.whl (2.9 kB)\n",
            "Requirement already satisfied: Keras-self-attention in /usr/local/lib/python3.7/dist-packages (0.35.0)\n",
            "Collecting style==1.1.0\n",
            "  Downloading style-1.1.0-py2.py3-none-any.whl (6.4 kB)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from Keras-self-attention) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from Keras-self-attention) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (6.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->Keras-self-attention) (2.10.0)\n",
            "Installing collected packages: style, update\n",
            "Successfully installed style-1.1.0 update-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7FNACE_zxGAU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7d7eb171-059c-43b3-f4d1-a1ab54d2e97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 511.7 MB 3.6 kB/s \n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 34.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.25.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Collecting numpy>=1.20\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 202 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (3.3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow-gpu) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: numpy, absl-py, tensorflow-estimator, tensorboard, keras, tensorflow-gpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
            "tensorflow 2.4.0 requires absl-py~=0.10, but you have absl-py 1.0.0 which is incompatible.\n",
            "tensorflow 2.4.0 requires numpy~=1.19.2, but you have numpy 1.21.6 which is incompatible.\n",
            "tensorflow 2.4.0 requires tensorflow-estimator<2.5.0,>=2.4.0rc0, but you have tensorflow-estimator 2.9.0 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.20.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas>=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-1.0.0 keras-2.9.0 numpy-1.21.6 tensorboard-2.9.0 tensorflow-estimator-2.9.0 tensorflow-gpu-2.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall -y tensorflow-gpu\n",
        "!pip install tensorflow-gpu #==1.14.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jLcxpJ64yhN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1aa58a1-ade2-4b81-be47-d65fddd7e37a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[autoreload of numpy failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "AttributeError: module 'numpy.core' has no attribute 'numerictypes'\n",
            "]\n",
            "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'type_check' is not defined\n",
            "]\n",
            "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name 'defmatrix' is not defined\n",
            "]\n",
            "[autoreload of numpy.linalg.linalg failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ValueError: Only callable can be used as callback\n",
            "]\n",
            "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "ValueError: Unknown input type\n",
            "]\n",
            "[autoreload of numpy.testing failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "NameError: name '_private' is not defined\n",
            "]\n",
            "[autoreload of numpy.testing._private.utils failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "AttributeError: module 'numpy.linalg' has no attribute 'lapack_lite'\n",
            "]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python3 --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwi20adLvXb4"
      },
      "source": [
        "## Install nltk "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMM9_MNSuhDX",
        "outputId": "efeb6eb7-0934-4353-c2f4-1810881ac80c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.4.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xudFAXzV8FL7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD09Et75qlqE"
      },
      "source": [
        " restart runtime and set default paths again\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xvBoEaeRlCW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "710a9f64-06d3-484b-d568-bda08063c866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ],
      "source": [
        "# check if GPU available then get information\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6OmK52wml4L",
        "outputId": "20d4c64f-20f5-4ad0-b1e9-fef0b684a682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wA2FekJlqdH",
        "outputId": "b749a0d8-1242-416b-ba9c-fb64b3523743"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow                    2.4.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.9.0\n",
            "tensorflow-gcs-config         2.8.0\n",
            "tensorflow-gpu                2.9.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.25.0\n",
            "tensorflow-metadata           1.8.0\n",
            "tensorflow-probability        0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip3  list | grep tensorflow #2.8 gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjO54f_svC-U",
        "outputId": "6a2d3337-6b18-448b-f780-f850329b0b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keras                         2.9.0\n",
            "keras-self-attention          0.35.0\n",
            "keras-vis                     0.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip3  list | grep  keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3_em86r-GBZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j_k_bj8TWvQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyloKHju6DIL"
      },
      "source": [
        "## Run the custom model with PubHealth data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNDnU0qpRTDK",
        "outputId": "5da50022-76ce-4723-e577-14e914840dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "train_df shape= (9804, 6)\n",
            "train_df features shape= (9804, 10, 24)\n",
            "Tokenizing text: 100% 1214/1214 [00:00<00:00, 14562.22it/s]\n",
            "Preparing input matrix: 1214it [00:00, 38805.96it/s]\n",
            "Tokenizing text: 100% 9804/9804 [00:00<00:00, 16596.23it/s]\n",
            "Preparing input matrix: 9804it [00:00, 41462.15it/s]\n",
            "Tokenizing text: 100% 1233/1233 [00:00<00:00, 14312.38it/s]\n",
            "Preparing input matrix: 1233it [00:00, 39283.96it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_PubHealth_10.check\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " features_input (InputLayer)  [(None, 10, 24)]         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 16)           1632      \n",
            " l)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " Embed_Layer (Embedding)        (None, 800, 300)     5105100     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 799, 16)      9616        ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 798, 16)      14416       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 797, 16)      19216       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 266, 16)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 265, 16)     0           ['conv1d_2[0][0]']               \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4256)         0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 4256)         0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 4240)         0           ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 12752)        0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,148,348\n",
            "Trainable params: 5,148,348\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 10, 800)]    0           []                               \n",
            "                                                                                                  \n",
            " input_sent2 (TimeDistributed)  (None, 10, 12752)    5148348     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " features_input (InputLayer)    [(None, 10, 24)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10, 8)        102024      ['input_sent2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 10, 32)       0           ['features_input[0][0]',         \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 10, 8)        264         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 10, 8)        0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 10, 16)       1632        ['features_input[0][0]']         \n",
            "                                                                                                  \n",
            " Self-Attention (SeqSelfAttenti  (None, 10, 8)       65          ['dropout[0][0]']                \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 16, 8)        0           ['bidirectional[0][0]',          \n",
            "                                                                  'Self-Attention[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 8)            0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 8)            72          ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 8)            0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " final_softmax (Dense)          (None, 4)            36          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,252,441\n",
            "Trainable params: 5,252,441\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= train\n",
            "Epoch 1/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 1.2158 - accuracy: 0.4168WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "76/76 [==============================] - 556s 7s/step - loss: 1.2158 - accuracy: 0.4168 - val_loss: 1.0944 - val_accuracy: 0.5180 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "76/76 [==============================] - 470s 6s/step - loss: 1.1345 - accuracy: 0.5000 - val_loss: 1.1049 - val_accuracy: 0.5183 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 1.1237 - accuracy: 0.5173WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "76/76 [==============================] - 468s 6s/step - loss: 1.1237 - accuracy: 0.5173 - val_loss: 1.0903 - val_accuracy: 0.5186 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 1.0805 - accuracy: 0.5461WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "76/76 [==============================] - 472s 6s/step - loss: 1.0805 - accuracy: 0.5461 - val_loss: 1.0316 - val_accuracy: 0.5192 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.9971 - accuracy: 0.5815WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, gru_cell_1_layer_call_fn, gru_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 7). These functions will not be directly callable after loading.\n",
            "76/76 [==============================] - 472s 6s/step - loss: 0.9971 - accuracy: 0.5815 - val_loss: 1.0001 - val_accuracy: 0.5620 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "76/76 [==============================] - 450s 6s/step - loss: 0.8977 - accuracy: 0.5914 - val_loss: 1.0011 - val_accuracy: 0.5853 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "76/76 [==============================] - 451s 6s/step - loss: 0.7991 - accuracy: 0.6557 - val_loss: 1.0385 - val_accuracy: 0.5733 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.7109\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "76/76 [==============================] - 453s 6s/step - loss: 0.6776 - accuracy: 0.7109 - val_loss: 1.1934 - val_accuracy: 0.5750 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "76/76 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.7438Restoring model weights from the end of the best epoch: 5.\n",
            "76/76 [==============================] - 457s 6s/step - loss: 0.6290 - accuracy: 0.7438 - val_loss: 1.2192 - val_accuracy: 0.5751 - lr: 3.0000e-05\n",
            "Epoch 9: early stopping\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       388\n",
            "           1       0.00      0.00      0.00       201\n",
            "           2       0.56      0.92      0.70       599\n",
            "           3       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.55      0.55      0.55      1233\n",
            "   macro avg       0.27      0.31      0.28      1233\n",
            "weighted avg       0.44      0.55      0.47      1233\n",
            "\n",
            "precision= 0.2713087664215484\n",
            "recall= 0.3135025299898456\n",
            "f1score= 0.27580877807541726\n"
          ]
        }
      ],
      "source": [
        "!python fake_flow.py -d PubHealth -sn 10 -m train -newproc True -epochs 20\n",
        "# !python fake_flow.py -d PubHealth -sn 10 -m train \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## other"
      ],
      "metadata": {
        "id": "tPugdyvXgJON"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1laXaK4Tiu5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ea863f-61a7-48d4-bcf2-3fcc29decd67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "train_df shape= (9804, 6)\n",
            "train_df features shape= (9804, 10, 24)\n",
            "Tokenizing text: 100% 1214/1214 [00:00<00:00, 17729.65it/s]\n",
            "Preparing input matrix: 1214it [00:00, 40898.02it/s]\n",
            "Tokenizing text: 100% 9804/9804 [00:00<00:00, 18253.74it/s]\n",
            "Preparing input matrix: 9804it [00:00, 34727.25it/s]\n",
            "Tokenizing text: 100% 1233/1233 [00:00<00:00, 19411.88it/s]\n",
            "Preparing input matrix: 1233it [00:00, 42881.71it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_PubHealth_10.check\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " features_input (InputLayer)  [(None, 10, 24)]         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 16)           1632      \n",
            " l)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " Embed_Layer (Embedding)        (None, 800, 300)     5105100     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 799, 16)      9616        ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 798, 16)      14416       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 797, 16)      19216       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 266, 16)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 265, 16)     0           ['conv1d_2[0][0]']               \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4256)         0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 4256)         0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 4240)         0           ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 12752)        0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,148,348\n",
            "Trainable params: 5,148,348\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 10, 800)]    0           []                               \n",
            "                                                                                                  \n",
            " input_sent2 (TimeDistributed)  (None, 10, 12752)    5148348     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " features_input (InputLayer)    [(None, 10, 24)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10, 8)        102024      ['input_sent2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 10, 32)       0           ['features_input[0][0]',         \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 10, 8)        264         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 10, 8)        0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 10, 16)       1632        ['features_input[0][0]']         \n",
            "                                                                                                  \n",
            " Self-Attention (SeqSelfAttenti  (None, 10, 8)       65          ['dropout[0][0]']                \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 16, 8)        0           ['bidirectional[0][0]',          \n",
            "                                                                  'Self-Attention[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 8)            0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 8)            72          ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 8)            0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " final_softmax (Dense)          (None, 4)            36          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,252,441\n",
            "Trainable params: 5,252,441\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= train\n",
            "Epoch 1/5\n",
            "2022-05-17 19:40:11.242585: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
            "2022-05-17 19:40:11.884455: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
            "2022-05-17 19:40:12.011319: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
            "2022-05-17 19:40:13.057241: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
            "2022-05-17 19:40:13.625069: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 153600000 exceeds 10% of free system memory.\n",
            "76/76 [==============================] - ETA: 0s - loss: 1.2158 - accuracy: 0.4168Traceback (most recent call last):\n",
            "  File \"fake_flow.py\", line 573, in <module>\n",
            "    EF.run_model(type_)\n",
            "  File \"fake_flow.py\", line 395, in run_model\n",
            "    validation_data=([self.dev['features'], self.dev['text']], self.dev['label']), callbacks=callback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1456, in fit\n",
            "    _use_cached_eval_dataset=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1756, in evaluate\n",
            "    tmp_logs = self.test_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 954, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2454, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1861, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 502, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# #test custom preprocess on Pubhealth data\n",
        "# !python custom_read_data.py\n",
        "# !python fake_flow.py -d PubHealth -sn 10 -m train -newproc True -epochs 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJH9ou_iReKR"
      },
      "source": [
        "## Load saved model for testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDr_hZbrRYyi",
        "outputId": "8da257ae-6d0e-4f4b-8a10-309b29c9d18c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "train_df shape= (9804, 6)\n",
            "train_df features shape= (9804, 10, 24)\n",
            "Tokenizing text: 100% 1214/1214 [00:00<00:00, 13402.27it/s]\n",
            "Preparing input matrix: 1214it [00:00, 36918.32it/s]\n",
            "Tokenizing text: 100% 9804/9804 [00:00<00:00, 17882.38it/s]\n",
            "Preparing input matrix: 9804it [00:00, 37099.12it/s]\n",
            "Tokenizing text: 100% 1233/1233 [00:00<00:00, 16195.19it/s]\n",
            "Preparing input matrix: 1233it [00:00, 40794.31it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_PubHealth_10.check\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " features_input (InputLayer)  [(None, 10, 24)]         0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 10, 16)           1632      \n",
            " l)                                                              \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 800)]        0           []                               \n",
            "                                                                                                  \n",
            " Embed_Layer (Embedding)        (None, 800, 300)     5105100     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 799, 16)      9616        ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 798, 16)      14416       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 797, 16)      19216       ['Embed_Layer[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 266, 16)      0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " average_pooling1d (AveragePool  (None, 265, 16)     0           ['conv1d_2[0][0]']               \n",
            " ing1D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 4256)         0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 4256)         0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 4240)         0           ['average_pooling1d[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 12752)        0           ['flatten[0][0]',                \n",
            "                                                                  'flatten_1[0][0]',              \n",
            "                                                                  'flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,148,348\n",
            "Trainable params: 5,148,348\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 10, 800)]    0           []                               \n",
            "                                                                                                  \n",
            " input_sent2 (TimeDistributed)  (None, 10, 12752)    5148348     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " features_input (InputLayer)    [(None, 10, 24)]     0           []                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 10, 8)        102024      ['input_sent2[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 10, 32)       0           ['features_input[0][0]',         \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 10, 8)        264         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 10, 8)        0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 10, 16)       1632        ['features_input[0][0]']         \n",
            "                                                                                                  \n",
            " Self-Attention (SeqSelfAttenti  (None, 10, 8)       65          ['dropout[0][0]']                \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 16, 8)        0           ['bidirectional[0][0]',          \n",
            "                                                                  'Self-Attention[0][0]']         \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 8)            0           ['dot[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 8)            72          ['lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 8)            0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " final_softmax (Dense)          (None, 4)            36          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 5,252,441\n",
            "Trainable params: 5,252,441\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= test\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       388\n",
            "           1       0.00      0.00      0.00       201\n",
            "           2       0.56      0.92      0.70       599\n",
            "           3       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.55      0.55      0.55      1233\n",
            "   macro avg       0.27      0.31      0.28      1233\n",
            "weighted avg       0.44      0.55      0.47      1233\n",
            "\n",
            "precision= 0.2713087664215484\n",
            "recall= 0.3135025299898456\n",
            "f1score= 0.27580877807541726\n",
            "--------Load Weights Successful!--------\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.33      0.41       388\n",
            "           1       0.00      0.00      0.00       201\n",
            "           2       0.56      0.92      0.70       599\n",
            "           3       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.55      0.55      0.55      1233\n",
            "   macro avg       0.27      0.31      0.28      1233\n",
            "weighted avg       0.44      0.55      0.47      1233\n",
            "\n",
            "precision= 0.2713087664215484\n",
            "recall= 0.3135025299898456\n",
            "f1score= 0.27580877807541726\n"
          ]
        }
      ],
      "source": [
        "!python fake_flow.py -d PubHealth -sn 10 -m test -newproc True\n",
        "# !python fake_flow.py -d PubHealth -sn 10 -m test \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82vIVLkC6Ibq"
      },
      "source": [
        "## Search for best params:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pczkq5tzRY12",
        "outputId": "1f5a4095-11a4-4601-d677-781f3f2bb015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "train_df shape= (9804, 6)\n",
            "train_df features shape= (9804, 10, 24)\n",
            "Tokenizing text: 100% 1214/1214 [00:00<00:00, 5752.14it/s]\n",
            "Preparing input matrix: 1214it [00:00, 9029.99it/s] \n",
            "Tokenizing text: 100% 9804/9804 [00:02<00:00, 3784.34it/s]\n",
            "Preparing input matrix: 9804it [00:00, 14233.64it/s]\n",
            "Tokenizing text: 100% 1233/1233 [00:00<00:00, 9431.45it/s] \n",
            "Preparing input matrix: 1233it [00:00, 10147.13it/s]\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 8, 'dense_3': 8, 'dropout': 0.39910793166643965, 'filter_sizes': (5,), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_PubHealth_10.check\n",
            "type= train\n",
            "Traceback (most recent call last):\n",
            "  File \"fake_flow.py\", line 575, in <module>\n",
            "    EF.run_hyperopt_search(args.search)\n",
            "  File \"fake_flow.py\", line 444, in run_hyperopt_search\n",
            "    best = fmin(self.objective_function, space=search_space, algo=tpe.suggest, max_evals=n_evals, trials=trials)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\", line 367, in fmin\n",
            "    return_argmin=return_argmin,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/base.py\", line 635, in fmin\n",
            "    return_argmin=return_argmin)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\", line 385, in fmin\n",
            "    rval.exhaust()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\", line 244, in exhaust\n",
            "    self.run(self.max_evals - n_done, block_until_done=self.asynchronous)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\", line 218, in run\n",
            "    self.serial_evaluate()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/fmin.py\", line 137, in serial_evaluate\n",
            "    result = self.domain.evaluate(spec, ctrl)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/hyperopt/base.py\", line 840, in evaluate\n",
            "    rval = self.fn(pyll_rval)\n",
            "  File \"fake_flow.py\", line 451, in objective_function\n",
            "    mean_score = self.Kstratified(params)\n",
            "  File \"fake_flow.py\", line 499, in Kstratified\n",
            "    self.run_model()\n",
            "  File \"fake_flow.py\", line 395, in run_model\n",
            "    validation_data=([self.dev['features'], self.dev['text']], self.dev['label']), callbacks=callback)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1456, in fit\n",
            "    _use_cached_eval_dataset=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1756, in evaluate\n",
            "    tmp_logs = self.test_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 915, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 954, in _call\n",
            "    results = self._stateful_fn(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 2454, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1861, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 502, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 55, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python fake_flow.py -d PubHealth -s 50 -newproc True -epochs 5\n",
        "# !python fake_flow.py -d PubHealth -s 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "185JEH4eeSb4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2DM2pmDkuaL"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfne6whkXXGy"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUhXyVjIjwnl"
      },
      "source": [
        "## Training with combined PubHealth and Recovery: use more data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1xcf5vb7kI2c"
      },
      "outputs": [],
      "source": [
        "# combine training sets PubHealth and ReCOVery train\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True -batch_size 16 -epochs 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HySxTybUkpif"
      },
      "outputs": [],
      "source": [
        "# # combine training sets PubHealth and ReCOVery and test on PubHealth\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m test -c True -batch_size 16 -epochs 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ESlNOCQyYJPD"
      },
      "outputs": [],
      "source": [
        "#search params for  previous experiment\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True -s 50 #-batch_size 16 -epochs 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10jIl8dghXE-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR8oqhjtMviD"
      },
      "source": [
        "## Use the original model\n",
        "We use a new preprocessing, various pooling(Max and average) and dropout after layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzXsg02ip3FF"
      },
      "source": [
        "### Training and testing with only PubHealth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um9wkZ-DM4x1",
        "outputId": "2c064837-6b06-4c07-d36d-ab92dc9a4b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-13 17:23:31.223984: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-13 17:23:32.669402: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-13 17:23:32.675908: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200150000 Hz\n",
            "2022-03-13 17:23:32.676169: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d49fcac680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-13 17:23:32.676211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-13 17:23:32.678763: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-13 17:23:32.692325: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-13 17:23:32.692378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0fdb8131f36a): /proc/driver/nvidia/version does not exist\n",
            "mypath= /content/drive/MyDrive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master\n",
            "preproc= True\n",
            "Text Segmentation:   0% 0/50 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 50/50 [00:00<00:00, 563.25it/s]\n",
            "Tokenizing text: 100% 34/34 [00:00<00:00, 1501.26it/s]\n",
            "Preparing input matrix: 34it [00:00, 1726.43it/s]\n",
            "Tokenizing text: 100% 9/9 [00:00<00:00, 2322.14it/s]\n",
            "Preparing input matrix: 9it [00:00, 2385.54it/s]\n",
            "Tokenizing text: 100% 7/7 [00:00<00:00, 2421.85it/s]\n",
            "Preparing input matrix: 7it [00:00, 2609.79it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "features_input (InputLayer)  [(None, 10, 24)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 16)            1632      \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed_Layer (Embedding)         (None, 800, 300)     1648500     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 799, 16)      9616        Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 798, 16)      14416       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 797, 16)      19216       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 266, 16)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 265, 16)      0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4256)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4256)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4240)         0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12752)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,691,748\n",
            "Trainable params: 1,691,748\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 10, 800)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_sent2 (TimeDistributed)   (None, 10, 12752)    1691748     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 8)        102024      input_sent2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "features_input (InputLayer)     [(None, 10, 24)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10, 8)        0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 32)       0           features_input[0][0]             \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 10, 32)       0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10, 8)        264         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 10, 16)       1632        features_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Self-Attention (SeqSelfAttentio (None, 10, 8)        65          dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 16, 8)        0           bidirectional[0][0]              \n",
            "                                                                 Self-Attention[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 8)            72          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 8)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "final_softmax (Dense)           (None, 2)            18          dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,795,823\n",
            "Trainable params: 1,795,823\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= train\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.4412WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "2022-03-13 17:23:50.064061: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6934 - accuracy: 0.4412 - val_loss: 0.6932 - val_accuracy: 0.5556\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6933 - accuracy: 0.5588 - val_loss: 0.6925 - val_accuracy: 0.5556\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6915 - accuracy: 0.5882 - val_loss: 0.6918 - val_accuracy: 0.5556\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6909 - accuracy: 0.5882 - val_loss: 0.6916 - val_accuracy: 0.5556\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 3s 847ms/step - loss: 0.6917 - accuracy: 0.5882 - val_loss: 0.6916 - val_accuracy: 0.5556\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6928 - accuracy: 0.5882 - val_loss: 0.6909 - val_accuracy: 0.5556\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6891 - accuracy: 0.5882 - val_loss: 0.6902 - val_accuracy: 0.5556\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6877 - accuracy: 0.5882 - val_loss: 0.6895 - val_accuracy: 0.5556\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 18s 6s/step - loss: 0.6870 - accuracy: 0.5882 - val_loss: 0.6888 - val_accuracy: 0.5556\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 3s 875ms/step - loss: 0.6855 - accuracy: 0.5882 - val_loss: 0.6892 - val_accuracy: 0.5556\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 3s 857ms/step - loss: 0.6845 - accuracy: 0.5882 - val_loss: 0.6890 - val_accuracy: 0.5556\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6805 - accuracy: 0.5882 - val_loss: 0.6884 - val_accuracy: 0.5556\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6717 - accuracy: 0.6176 - val_loss: 0.6869 - val_accuracy: 0.5556\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 19s 6s/step - loss: 0.6697 - accuracy: 0.5882 - val_loss: 0.6866 - val_accuracy: 0.5556\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 3s 871ms/step - loss: 0.6832 - accuracy: 0.5000 - val_loss: 0.6966 - val_accuracy: 0.5556\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 3s 937ms/step - loss: 0.6771 - accuracy: 0.5882 - val_loss: 0.7075 - val_accuracy: 0.5556\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6188 - accuracy: 0.6176\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "3/3 [==============================] - 3s 847ms/step - loss: 0.6188 - accuracy: 0.6176 - val_loss: 0.7006 - val_accuracy: 0.5556\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6349 - accuracy: 0.6471Restoring model weights from the end of the best epoch.\n",
            "3/3 [==============================] - 3s 845ms/step - loss: 0.6349 - accuracy: 0.6471 - val_loss: 0.6999 - val_accuracy: 0.5556\n",
            "Epoch 00018: early stopping\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy= 0.7142857142857143\n"
          ]
        }
      ],
      "source": [
        "!python fake_flow.py -d PubHealth -sn 10 -m train "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cKwqHstphpM",
        "outputId": "635eda10-287b-4c21-8ac5-989f9abfb096"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-13 17:28:06.232953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-13 17:28:07.669867: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-13 17:28:07.679396: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200150000 Hz\n",
            "2022-03-13 17:28:07.679680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ba7df7c680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-13 17:28:07.679731: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-13 17:28:07.682002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-13 17:28:07.705875: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-13 17:28:07.705933: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0fdb8131f36a): /proc/driver/nvidia/version does not exist\n",
            "mypath= /content/drive/MyDrive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master\n",
            "preproc= True\n",
            "Text Segmentation:   0% 0/50 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 50/50 [00:00<00:00, 498.69it/s]\n",
            "Tokenizing text: 100% 34/34 [00:00<00:00, 1477.62it/s]\n",
            "Preparing input matrix: 34it [00:00, 1698.18it/s]\n",
            "Tokenizing text: 100% 9/9 [00:00<00:00, 2285.31it/s]\n",
            "Preparing input matrix: 9it [00:00, 2385.39it/s]\n",
            "Tokenizing text: 100% 7/7 [00:00<00:00, 2421.85it/s]\n",
            "Preparing input matrix: 7it [00:00, 2488.78it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "features_input (InputLayer)  [(None, 10, 24)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 16)            1632      \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed_Layer (Embedding)         (None, 800, 300)     1648500     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 799, 16)      9616        Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 798, 16)      14416       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 797, 16)      19216       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 266, 16)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 265, 16)      0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4256)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4256)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4240)         0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12752)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,691,748\n",
            "Trainable params: 1,691,748\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 10, 800)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_sent2 (TimeDistributed)   (None, 10, 12752)    1691748     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "features_input (InputLayer)     [(None, 10, 24)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 8)        102024      input_sent2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 32)       0           features_input[0][0]             \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10, 8)        264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10, 8)        0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 10, 16)       1632        features_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Self-Attention (SeqSelfAttentio (None, 10, 8)        65          dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 16, 8)        0           bidirectional[0][0]              \n",
            "                                                                 Self-Attention[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 8)            72          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 8)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "final_softmax (Dense)           (None, 2)            18          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,795,823\n",
            "Trainable params: 1,795,823\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= test\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fd8a434de90> and <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fd8a78f2910>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fd8a78f2a50> and <tensorflow.python.keras.layers.wrappers.Bidirectional object at 0x7fd8af66df10>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.wrappers.Bidirectional object at 0x7fd8af66df10> and <self_attention.SeqSelfAttention object at 0x7fd8a42fe0d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<self_attention.SeqSelfAttention object at 0x7fd8a42fe0d0> and <tensorflow.python.keras.layers.merge.Dot object at 0x7fd8a4320750>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fd8a413f650> and <tensorflow.python.keras.layers.core.Dropout object at 0x7fd8a4119810>).\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy= 0.7142857142857143\n",
            "--------Load Weights Successful!--------\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy= 0.7142857142857143\n"
          ]
        }
      ],
      "source": [
        "# Load saved model\n",
        "!python fake_flow.py -d PubHealth -sn 10 -m test \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD8YPZ_kpcj-",
        "outputId": "4cc235cc-ab66-42a9-d431-19b463e2f577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-13 11:29:29.374703: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-13 11:29:30.840346: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-13 11:29:30.846617: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200150000 Hz\n",
            "2022-03-13 11:29:30.846883: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559832b92680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-13 11:29:30.846926: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-13 11:29:30.849386: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-13 11:29:30.863462: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-13 11:29:30.863543: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0fdb8131f36a): /proc/driver/nvidia/version does not exist\n",
            "mypath= /content/drive/MyDrive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master\n",
            "preproc= True\n",
            "Text Segmentation:   0% 0/50 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 50/50 [00:00<00:00, 537.56it/s]\n",
            "Tokenizing text: 100% 34/34 [00:00<00:00, 1488.82it/s]\n",
            "Preparing input matrix: 34it [00:00, 2121.27it/s]\n",
            "Tokenizing text: 100% 9/9 [00:00<00:00, 2256.89it/s]\n",
            "Preparing input matrix: 9it [00:00, 2309.64it/s]\n",
            "Tokenizing text: 100% 7/7 [00:00<00:00, 2398.90it/s]\n",
            "Preparing input matrix: 7it [00:00, 2481.00it/s]\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': 16, 'dense_2': 8, 'dense_3': 128, 'dropout': 0.5862059461892672, 'filter_sizes': (2, 4), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00022: early stopping\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.75      0.75      0.75         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.78      0.78      0.78         9\n",
            "weighted avg       0.78      0.78      0.78         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.33      0.50      0.40         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.54      0.55      0.53         7\n",
            "weighted avg       0.63      0.57      0.59         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.4\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': '16', 'dense_2': '8', 'dense_3': '128', 'dropout': '0.5862059461892672', 'filter_sizes': '(2, 4)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.7750000000000001'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 8, 'dense_3': 128, 'dropout': 0.5391256549582722, 'filter_sizes': (3, 5, 7), 'num_filters': 16, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '8', 'dense_3': '128', 'dropout': '0.5391256549582722', 'filter_sizes': '(3, 5, 7)', 'num_filters': '16', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': 64, 'dense_2': 16, 'dense_3': 32, 'dropout': 0.513432317419511, 'filter_sizes': (4, 5, 6), 'num_filters': 16, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': '64', 'dense_2': '16', 'dense_3': '32', 'dropout': '0.513432317419511', 'filter_sizes': '(4, 5, 6)', 'num_filters': '16', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': 128, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.24333089115040743, 'filter_sizes': (2, 3, 4), 'num_filters': 8, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00010: early stopping\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': '128', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.24333089115040743', 'filter_sizes': '(2, 3, 4)', 'num_filters': '8', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': 64, 'dense_2': 32, 'dense_3': 16, 'dropout': 0.5465130142270922, 'filter_sizes': (4, 5, 6), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8524af830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': '64', 'dense_2': '32', 'dense_3': '16', 'dropout': '0.5465130142270922', 'filter_sizes': '(4, 5, 6)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.3894586500330933, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc85c0c4710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.3894586500330933', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 32, 'dense_2': 16, 'dense_3': 32, 'dropout': 0.5933179238864884, 'filter_sizes': (2, 3, 4), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8582013b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '32', 'dense_2': '16', 'dense_3': '32', 'dropout': '0.5933179238864884', 'filter_sizes': '(2, 3, 4)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'elu', 'dense_1': 8, 'dense_2': 8, 'dense_3': 8, 'dropout': 0.26601243635392946, 'filter_sizes': (2, 3, 4), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc857428320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'elu', 'dense_1': '8', 'dense_2': '8', 'dense_3': '8', 'dropout': '0.26601243635392946', 'filter_sizes': '(2, 3, 4)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': 8, 'dense_2': 32, 'dense_3': 16, 'dropout': 0.2995974569951184, 'filter_sizes': (3, 6), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8524af320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': '8', 'dense_2': '32', 'dense_3': '16', 'dropout': '0.2995974569951184', 'filter_sizes': '(3, 6)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': 16, 'dense_2': 64, 'dense_3': 32, 'dropout': 0.12333232793129126, 'filter_sizes': (2, 4), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8572e8440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': '16', 'dense_2': '64', 'dense_3': '32', 'dropout': '0.12333232793129126', 'filter_sizes': '(2, 4)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 16, 'dense_2': 8, 'dense_3': 128, 'dropout': 0.595067338089241, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8575987a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '16', 'dense_2': '8', 'dense_3': '128', 'dropout': '0.595067338089241', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 32, 'dense_3': 128, 'dropout': 0.3074815016128233, 'filter_sizes': (4, 5, 6), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc85be3a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '32', 'dense_3': '128', 'dropout': '0.3074815016128233', 'filter_sizes': '(4, 5, 6)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': 32, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.5921894731403331, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84e399560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': '32', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.5921894731403331', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'elu', 'dense_1': 8, 'dense_2': 32, 'dense_3': 32, 'dropout': 0.5462373589310909, 'filter_sizes': (2, 3, 4), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84e117830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'elu', 'dense_1': '8', 'dense_2': '32', 'dense_3': '32', 'dropout': '0.5462373589310909', 'filter_sizes': '(2, 3, 4)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 64, 'dense_2': 8, 'dense_3': 64, 'dropout': 0.12888551849551397, 'filter_sizes': (4,), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc85c0c40e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '64', 'dense_2': '8', 'dense_3': '64', 'dropout': '0.12888551849551397', 'filter_sizes': '(4,)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': 64, 'dense_2': 8, 'dense_3': 32, 'dropout': 0.18249288888571555, 'filter_sizes': (3, 5), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00023: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8572bcb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91         5\n",
            "           1       1.00      0.75      0.86         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.92      0.88      0.88         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': '64', 'dense_2': '8', 'dense_3': '32', 'dropout': '0.18249288888571555', 'filter_sizes': '(3, 5)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.8831168831168831'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': 128, 'dense_2': 8, 'dense_3': 32, 'dropout': 0.47472628940650274, 'filter_sizes': (3, 5, 7), 'num_filters': 8, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00005: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8524af3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': '128', 'dense_2': '8', 'dense_3': '32', 'dropout': '0.47472628940650274', 'filter_sizes': '(3, 5, 7)', 'num_filters': '8', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': 16, 'dense_2': 16, 'dense_3': 32, 'dropout': 0.4993082455664052, 'filter_sizes': (3, 6), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84575ab90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': '16', 'dense_2': '16', 'dense_3': '32', 'dropout': '0.4993082455664052', 'filter_sizes': '(3, 6)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.37341605774851117, 'filter_sizes': (3, 5), 'num_filters': 4, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8571a0d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.37341605774851117', 'filter_sizes': '(3, 5)', 'num_filters': '4', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': 32, 'dense_2': 128, 'dense_3': 128, 'dropout': 0.17044198634597077, 'filter_sizes': (2, 4), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc85822a710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'relu', 'dense_1': '32', 'dense_2': '128', 'dense_3': '128', 'dropout': '0.17044198634597077', 'filter_sizes': '(2, 4)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': 8, 'dense_2': 128, 'dense_3': 16, 'dropout': 0.40349190056611495, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84159c3b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': '8', 'dense_2': '128', 'dense_3': '16', 'dropout': '0.40349190056611495', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': 64, 'dense_2': 64, 'dense_3': 128, 'dropout': 0.410542186328619, 'filter_sizes': (5,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00016: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8572c4b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.57      1.00      0.73         4\n",
            "\n",
            "   micro avg       0.67      0.67      0.67         9\n",
            "   macro avg       0.79      0.70      0.65         9\n",
            "weighted avg       0.81      0.67      0.64         9\n",
            "\n",
            "accuracy= 0.6666666666666666\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': '64', 'dense_2': '64', 'dense_3': '128', 'dropout': '0.410542186328619', 'filter_sizes': '(5,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.6493506493506493'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 8, 'dense_2': 128, 'dense_3': 64, 'dropout': 0.18400617031479097, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84e22f4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.67      1.00      0.80         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.83      0.80      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "   micro avg       0.86      0.86      0.86         7\n",
            "   macro avg       0.83      0.90      0.84         7\n",
            "weighted avg       0.90      0.86      0.86         7\n",
            "\n",
            "accuracy test= 0.8571428571428571\n",
            "f1 score test= 0.8\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '8', 'dense_2': '128', 'dense_3': '64', 'dropout': '0.18400617031479097', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.7749999999999999'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': 128, 'dense_2': 64, 'dense_3': 128, 'dropout': 0.4305001465755134, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8457acd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': '128', 'dense_2': '64', 'dense_3': '128', 'dropout': '0.4305001465755134', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': 64, 'dense_2': 8, 'dense_3': 32, 'dropout': 0.35289515708281155, 'filter_sizes': (3, 5), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc842a77320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': '64', 'dense_2': '8', 'dense_3': '32', 'dropout': '0.35289515708281155', 'filter_sizes': '(3, 5)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.20909736610471055, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc851f7d290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.33      0.50      0.40         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.54      0.55      0.53         7\n",
            "weighted avg       0.63      0.57      0.59         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.4\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.20909736610471055', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.2557931526861923, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc84569f050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.2557931526861923', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.3114440833505427, 'filter_sizes': (5,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc845caeb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.3114440833505427', 'filter_sizes': '(5,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.2208101275678789, 'filter_sizes': (4,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00020: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc841749d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.57      1.00      0.73         4\n",
            "\n",
            "   micro avg       0.67      0.67      0.67         9\n",
            "   macro avg       0.79      0.70      0.65         9\n",
            "weighted avg       0.81      0.67      0.64         9\n",
            "\n",
            "accuracy= 0.6666666666666666\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "   micro avg       0.86      0.86      0.86         7\n",
            "   macro avg       0.83      0.90      0.84         7\n",
            "weighted avg       0.90      0.86      0.86         7\n",
            "\n",
            "accuracy test= 0.8571428571428571\n",
            "f1 score test= 0.8\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.2208101275678789', 'filter_sizes': '(4,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.6493506493506493'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.45670654901457836, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00010: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc845b4f560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.45670654901457836', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.367706579385871, 'filter_sizes': (3, 5), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc842a77b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.367706579385871', 'filter_sizes': '(3, 5)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.3274551260214845, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00021: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8379a53b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "   micro avg       1.00      1.00      1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "accuracy= 1.0\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.3274551260214845', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '1.0'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 64, 'dense_3': 8, 'dropout': 0.3348958093338876, 'filter_sizes': (5,), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00005: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc841266b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.80      0.73         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.33      0.40      0.36         7\n",
            "weighted avg       0.48      0.57      0.52         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': '128', 'dense_2': '64', 'dense_3': '8', 'dropout': '0.3348958093338876', 'filter_sizes': '(5,)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 32, 'dense_2': 128, 'dense_3': 16, 'dropout': 0.21854975832697124, 'filter_sizes': (3, 6), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc83b5d8200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '32', 'dense_2': '128', 'dense_3': '16', 'dropout': '0.21854975832697124', 'filter_sizes': '(3, 6)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.15415130270936261, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00021: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8372ae4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.15415130270936261', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.10589489000436686, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc833ca1710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "   micro avg       1.00      1.00      1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "accuracy= 1.0\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.10589489000436686', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '1.0'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 16, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.10693412164132457, 'filter_sizes': (3, 4, 5), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc833a6d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '16', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.10693412164132457', 'filter_sizes': '(3, 4, 5)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 32, 'dense_3': 64, 'dropout': 0.26004185630271165, 'filter_sizes': (3, 4, 5), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00007: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc829c37320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': '128', 'dense_2': '32', 'dense_3': '64', 'dropout': '0.26004185630271165', 'filter_sizes': '(3, 4, 5)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.28992306065155793, 'filter_sizes': (4, 5, 6), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00018: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc83780e830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91         5\n",
            "           1       1.00      0.75      0.86         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.92      0.88      0.88         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.28992306065155793', 'filter_sizes': '(4, 5, 6)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.8831168831168831'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 32, 'dense_2': 64, 'dense_3': 8, 'dropout': 0.5097818739272018, 'filter_sizes': (2, 4), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00007: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc833c554d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '32', 'dense_2': '64', 'dense_3': '8', 'dropout': '0.5097818739272018', 'filter_sizes': '(2, 4)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.10025633308107396, 'filter_sizes': (3, 5, 7), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc837863c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.10025633308107396', 'filter_sizes': '(3, 5, 7)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': 16, 'dense_2': 32, 'dense_3': 16, 'dropout': 0.3319113963199074, 'filter_sizes': (3, 4, 5), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc837603cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': '16', 'dense_2': '32', 'dense_3': '16', 'dropout': '0.3319113963199074', 'filter_sizes': '(3, 4, 5)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 128, 'dense_3': 64, 'dropout': 0.2783640140797617, 'filter_sizes': (4,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00005: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8264f5560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '128', 'dense_3': '64', 'dropout': '0.2783640140797617', 'filter_sizes': '(4,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.14566761057957, 'filter_sizes': (2, 3, 4), 'num_filters': 16, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8416decb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.14566761057957', 'filter_sizes': '(2, 3, 4)', 'num_filters': '16', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 16, 'dense_3': 16, 'dropout': 0.5651392027286269, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc824c35680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '128', 'dense_2': '16', 'dense_3': '16', 'dropout': '0.5651392027286269', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': 32, 'dense_2': 32, 'dense_3': 64, 'dropout': 0.43557423923372024, 'filter_sizes': (4, 5, 6), 'num_filters': 8, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00007: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc845c4d290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'selu', 'dense_1': '32', 'dense_2': '32', 'dense_3': '64', 'dropout': '0.43557423923372024', 'filter_sizes': '(4, 5, 6)', 'num_filters': '8', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 16, 'dense_2': 64, 'dense_3': 8, 'dropout': 0.48295748255158755, 'filter_sizes': (3, 6), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82c2b0830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '16', 'dense_2': '64', 'dense_3': '8', 'dropout': '0.48295748255158755', 'filter_sizes': '(3, 6)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 8, 'dense_3': 64, 'dropout': 0.23597015737968424, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8261b07a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '8', 'dense_3': '64', 'dropout': '0.23597015737968424', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': 8, 'dense_2': 16, 'dense_3': 16, 'dropout': 0.11387122120765172, 'filter_sizes': (2, 3, 4), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc832fa67a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.60      0.75      0.67         4\n",
            "\n",
            "   micro avg       0.67      0.67      0.67         9\n",
            "   macro avg       0.68      0.68      0.67         9\n",
            "weighted avg       0.68      0.67      0.67         9\n",
            "\n",
            "accuracy= 0.6666666666666666\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.20      0.29         5\n",
            "           1       0.20      0.50      0.29         2\n",
            "\n",
            "   micro avg       0.29      0.29      0.29         7\n",
            "   macro avg       0.35      0.35      0.29         7\n",
            "weighted avg       0.41      0.29      0.29         7\n",
            "\n",
            "accuracy test= 0.2857142857142857\n",
            "f1 score test= 0.28571428571428575\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'selu', 'dense_1': '8', 'dense_2': '16', 'dense_3': '16', 'dropout': '0.11387122120765172', 'filter_sizes': '(2, 3, 4)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.6666666666666665'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': 16, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.5596681117417742, 'filter_sizes': (2, 4), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82624b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': '16', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.5596681117417742', 'filter_sizes': '(2, 4)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': 32, 'dense_2': 32, 'dense_3': 32, 'dropout': 0.5210672356122007, 'filter_sizes': (4,), 'num_filters': 8, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8192a9cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': '32', 'dense_2': '32', 'dense_3': '32', 'dropout': '0.5210672356122007', 'filter_sizes': '(4,)', 'num_filters': '8', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 128, 'dense_3': 64, 'dropout': 0.2022414444503781, 'filter_sizes': (5,), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00018: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8375c1680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.57      1.00      0.73         4\n",
            "\n",
            "   micro avg       0.67      0.67      0.67         9\n",
            "   macro avg       0.79      0.70      0.65         9\n",
            "weighted avg       0.81      0.67      0.64         9\n",
            "\n",
            "accuracy= 0.6666666666666666\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '128', 'dense_3': '64', 'dropout': '0.2022414444503781', 'filter_sizes': '(5,)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.6493506493506493'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'relu', 'dense_1': 8, 'dense_2': 8, 'dense_3': 128, 'dropout': 0.23997050830765382, 'filter_sizes': (4, 5, 6), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc833f40680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'relu', 'dense_1': '8', 'dense_2': '8', 'dense_3': '128', 'dropout': '0.23997050830765382', 'filter_sizes': '(4, 5, 6)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 128, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.13947344174476625, 'filter_sizes': (3, 4, 5), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82c69e8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '128', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.13947344174476625', 'filter_sizes': '(3, 4, 5)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': 8, 'dense_2': 64, 'dense_3': 32, 'dropout': 0.3931131622131404, 'filter_sizes': (3, 6), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc81be85e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': '8', 'dense_2': '64', 'dense_3': '32', 'dropout': '0.3931131622131404', 'filter_sizes': '(3, 6)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.16991730832349006, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00022: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82624b4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "   micro avg       1.00      1.00      1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "accuracy= 1.0\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.16991730832349006', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '1.0'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': 64, 'dense_2': 128, 'dense_3': 64, 'dropout': 0.15983367919872102, 'filter_sizes': (3, 5, 7), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00010: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82c44af80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': '64', 'dense_2': '128', 'dense_3': '64', 'dropout': '0.15983367919872102', 'filter_sizes': '(3, 5, 7)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 8, 'dense_2': 8, 'dense_3': 128, 'dropout': 0.3116540453961437, 'filter_sizes': (3, 5), 'num_filters': 4, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc817c453b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '8', 'dense_2': '8', 'dense_3': '128', 'dropout': '0.3116540453961437', 'filter_sizes': '(3, 5)', 'num_filters': '4', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '16', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.18994700170278353, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00018: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc83392c320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.57      1.00      0.73         4\n",
            "\n",
            "   micro avg       0.67      0.67      0.67         9\n",
            "   macro avg       0.79      0.70      0.65         9\n",
            "weighted avg       0.81      0.67      0.64         9\n",
            "\n",
            "accuracy= 0.6666666666666666\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.40      1.00      0.57         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.70      0.70      0.57         7\n",
            "weighted avg       0.83      0.57      0.57         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.5714285714285715\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.18994700170278353', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.6493506493506493'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 32, 'dense_3': 64, 'dropout': 0.13336400519354533, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00011: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc818df08c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.67      1.00      0.80         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.83      0.80      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '32', 'dense_3': '64', 'dropout': '0.13336400519354533', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '128', 'score': '0.7749999999999999'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'selu', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.1745645178252279, 'filter_sizes': (3, 5, 7), 'num_filters': 32, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00008: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc81c2a7440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'selu', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.1745645178252279', 'filter_sizes': '(3, 5, 7)', 'num_filters': '32', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 64, 'dense_3': 128, 'dropout': 0.37531100055003164, 'filter_sizes': (2, 4), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00019: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc81c14b170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "   micro avg       0.86      0.86      0.86         7\n",
            "   macro avg       0.83      0.90      0.84         7\n",
            "weighted avg       0.90      0.86      0.86         7\n",
            "\n",
            "accuracy test= 0.8571428571428571\n",
            "f1 score test= 0.8\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '64', 'dense_3': '128', 'dropout': '0.37531100055003164', 'filter_sizes': '(2, 4)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.11931894371779457, 'filter_sizes': (2, 3, 4), 'num_filters': 16, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00022: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80ebb1560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'relu', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.11931894371779457', 'filter_sizes': '(2, 3, 4)', 'num_filters': '16', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': 64, 'dense_2': 8, 'dense_3': 16, 'dropout': 0.3348953100009534, 'filter_sizes': (3, 5, 7), 'num_filters': 8, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc818ed34d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'elu', 'dense_1': '64', 'dense_2': '8', 'dense_3': '16', 'dropout': '0.3348953100009534', 'filter_sizes': '(3, 5, 7)', 'num_filters': '8', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 32, 'dense_2': 128, 'dense_3': 32, 'dropout': 0.4191824616195179, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00008: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc808996b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '32', 'dense_2': '128', 'dense_3': '32', 'dropout': '0.4191824616195179', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.28031419959242987, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00019: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc832f49560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.33      0.50      0.40         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.54      0.55      0.53         7\n",
            "weighted avg       0.63      0.57      0.59         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.4\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.28031419959242987', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 16, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.4516514894444028, 'filter_sizes': (4,), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc818a4db00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '16', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.4516514894444028', 'filter_sizes': '(4,)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.1631217560392713, 'filter_sizes': (5,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc807b64f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       1.00      0.50      0.67         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.86      0.75      0.75         9\n",
            "weighted avg       0.84      0.78      0.76         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.80      0.73         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.33      0.40      0.36         7\n",
            "weighted avg       0.48      0.57      0.52         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': '128', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.1631217560392713', 'filter_sizes': '(5,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.75'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.19822774545686636, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00020: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc819b9e320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.67      1.00      0.80         2\n",
            "\n",
            "   micro avg       0.86      0.86      0.86         7\n",
            "   macro avg       0.83      0.90      0.84         7\n",
            "weighted avg       0.90      0.86      0.86         7\n",
            "\n",
            "accuracy test= 0.8571428571428571\n",
            "f1 score test= 0.8\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.19822774545686636', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.21960848054873172, 'filter_sizes': (3, 5, 7), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc817d79cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.21960848054873172', 'filter_sizes': '(3, 5, 7)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.25397448362803793, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80846ae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.25397448362803793', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 64, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.35049635081020825, 'filter_sizes': (4, 5, 6), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00010: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc81bdcac20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '64', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.35049635081020825', 'filter_sizes': '(4, 5, 6)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 16, 'dense_3': 16, 'dropout': 0.3203993361831862, 'filter_sizes': (3, 6), 'num_filters': 4, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc82c6103b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '16', 'dropout': '0.3203993361831862', 'filter_sizes': '(3, 6)', 'num_filters': '4', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '8', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 32, 'dense_2': 16, 'dense_3': 64, 'dropout': 0.2732864950573195, 'filter_sizes': (3, 5), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 32}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00010: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc807f5b710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '32', 'dense_2': '16', 'dense_3': '64', 'dropout': '0.2732864950573195', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '32', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': 128, 'dense_2': 32, 'dense_3': 32, 'dropout': 0.229399371365219, 'filter_sizes': (2, 4), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 16}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00032: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc820ffc440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.75      0.75      0.75         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.78      0.78      0.78         9\n",
            "weighted avg       0.78      0.78      0.78         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.40      1.00      0.57         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.70      0.70      0.57         7\n",
            "weighted avg       0.83      0.57      0.57         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.5714285714285715\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'selu', 'activation_rnn': 'tanh', 'dense_1': '128', 'dense_2': '32', 'dense_3': '32', 'dropout': '0.229399371365219', 'filter_sizes': '(2, 4)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '16', 'score': '0.7750000000000001'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': 16, 'dense_2': 16, 'dense_3': 128, 'dropout': 0.29514097191622335, 'filter_sizes': (3, 4, 5), 'num_filters': 64, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00019: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80846a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.67      1.00      0.80         4\n",
            "\n",
            "   micro avg       0.78      0.78      0.78         9\n",
            "   macro avg       0.83      0.80      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "accuracy= 0.7777777777777778\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.60      0.75         5\n",
            "           1       0.50      1.00      0.67         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.75      0.80      0.71         7\n",
            "weighted avg       0.86      0.71      0.73         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.6666666666666666\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'elu', 'activation_rnn': 'tanh', 'dense_1': '16', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.29514097191622335', 'filter_sizes': '(3, 4, 5)', 'num_filters': '64', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.7749999999999999'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': 8, 'dense_2': 64, 'dense_3': 64, 'dropout': 0.14289025699721813, 'filter_sizes': (2, 3, 4), 'num_filters': 16, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc8088db200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.80      0.67         5\n",
            "           1       0.50      0.25      0.33         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.54      0.53      0.50         9\n",
            "weighted avg       0.54      0.56      0.52         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.60      0.67         5\n",
            "           1       0.33      0.50      0.40         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.54      0.55      0.53         7\n",
            "weighted avg       0.63      0.57      0.59         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.4\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'relu', 'dense_1': '8', 'dense_2': '64', 'dense_3': '64', 'dropout': '0.14289025699721813', 'filter_sizes': '(2, 3, 4)', 'num_filters': '16', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.5'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': 8, 'dense_2': 16, 'dense_3': 8, 'dropout': 0.17851392290574325, 'filter_sizes': (3, 5, 7), 'num_filters': 32, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 128}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00006: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc7fbbb73b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      1.00      0.71         5\n",
            "           1       0.00      0.00      0.00         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.28      0.50      0.36         9\n",
            "weighted avg       0.31      0.56      0.40         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      1.00      0.83         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.36      0.50      0.42         7\n",
            "weighted avg       0.51      0.71      0.60         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'relu', 'activation_rnn': 'selu', 'dense_1': '8', 'dense_2': '16', 'dense_3': '8', 'dropout': '0.17851392290574325', 'filter_sizes': '(3, 5, 7)', 'num_filters': '32', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '128', 'score': '0.35714285714285715'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': 64, 'dense_2': 128, 'dense_3': 128, 'dropout': 0.10274955730011064, 'filter_sizes': (3, 5), 'num_filters': 4, 'optimizer': 'adam', 'pool_size': 2, 'rnn_size': 64}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00017: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc80b8aa200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.80      1.00      0.89         4\n",
            "\n",
            "   micro avg       0.89      0.89      0.89         9\n",
            "   macro avg       0.90      0.90      0.89         9\n",
            "weighted avg       0.91      0.89      0.89         9\n",
            "\n",
            "accuracy= 0.8888888888888888\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.80      0.80         5\n",
            "           1       0.50      0.50      0.50         2\n",
            "\n",
            "   micro avg       0.71      0.71      0.71         7\n",
            "   macro avg       0.65      0.65      0.65         7\n",
            "weighted avg       0.71      0.71      0.71         7\n",
            "\n",
            "accuracy test= 0.7142857142857143\n",
            "f1 score test= 0.5\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'elu', 'dense_1': '64', 'dense_2': '128', 'dense_3': '128', 'dropout': '0.10274955730011064', 'filter_sizes': '(3, 5)', 'num_filters': '4', 'optimizer': 'adam', 'pool_size': '2', 'rnn_size': '64', 'score': '0.888888888888889'}\n",
            "Current: {'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': 8, 'dense_2': 8, 'dense_3': 64, 'dropout': 0.11823878361764209, 'filter_sizes': (5,), 'num_filters': 64, 'optimizer': 'rmsprop', 'pool_size': 2, 'rnn_size': 8}\n",
            "file= ./processed_files/saved_models/fake_flow_MultiSourceFake_10.check\n",
            "type= train\n",
            "\n",
            "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00009: early stopping\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc818cf5200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "classification_report=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.57      0.80      0.67         5\n",
            "           1       0.50      0.25      0.33         4\n",
            "\n",
            "   micro avg       0.56      0.56      0.56         9\n",
            "   macro avg       0.54      0.53      0.50         9\n",
            "weighted avg       0.54      0.56      0.52         9\n",
            "\n",
            "accuracy= 0.5555555555555556\n",
            "-----------on test--------------\n",
            "report test=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.80      0.73         5\n",
            "           1       0.00      0.00      0.00         2\n",
            "\n",
            "   micro avg       0.57      0.57      0.57         7\n",
            "   macro avg       0.33      0.40      0.36         7\n",
            "weighted avg       0.48      0.57      0.52         7\n",
            "\n",
            "accuracy test= 0.5714285714285714\n",
            "f1 score test= 0.0\n",
            "\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '8', 'dense_3': '64', 'dropout': '0.11823878361764209', 'filter_sizes': '(5,)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '8', 'score': '0.5'}\n",
            "\n",
            "\n",
            " {'activation_attention': 0, 'activation_cnn': 2, 'activation_rnn': 2, 'dense_1': 0, 'dense_2': 1, 'dense_3': 4, 'dropout': 0.3274551260214845, 'filter_sizes': 3, 'num_filters': 4, 'optimizer': 1, 'pool_size': 0, 'rnn_size': 3}\n",
            "{'activation_attention': 'sigmoid', 'activation_cnn': 'tanh', 'activation_rnn': 'tanh', 'dense_1': '8', 'dense_2': '16', 'dense_3': '128', 'dropout': '0.3274551260214845', 'filter_sizes': '(3, 5)', 'num_filters': '64', 'optimizer': 'rmsprop', 'pool_size': '2', 'rnn_size': '64', 'score': '1.0'}\n"
          ]
        }
      ],
      "source": [
        "#search best params\n",
        "!python fake_flow.py -d PubHealth -s 50 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-NKIJWgBT61"
      },
      "source": [
        "### Training with combined PubHealth and Recovery"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V00Mk8NFBXLi",
        "outputId": "f4d71988-f564-41ae-a3e7-1f69b63ce2ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-13 17:58:54.957972: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-13 17:58:56.413077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-13 17:58:56.419309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200150000 Hz\n",
            "2022-03-13 17:58:56.419591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55835a9f6680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-13 17:58:56.419639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-13 17:58:56.421970: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-13 17:58:56.435853: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-13 17:58:56.435911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0fdb8131f36a): /proc/driver/nvidia/version does not exist\n",
            "mypath= /content/drive/MyDrive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master\n",
            "preproc= True\n",
            "Text Segmentation:   0% 0/50 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 50/50 [00:00<00:00, 540.89it/s]\n",
            "Text Segmentation:   0% 0/2029 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   1% 27/2029 [00:00<00:07, 262.75it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   3% 58/2029 [00:00<00:07, 273.46it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   5% 93/2029 [00:00<00:06, 288.73it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   6% 128/2029 [00:00<00:06, 304.63it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   8% 161/2029 [00:00<00:06, 310.90it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   9% 192/2029 [00:00<00:05, 309.35it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  11% 225/2029 [00:00<00:05, 313.84it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  13% 259/2029 [00:00<00:05, 318.98it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  14% 290/2029 [00:00<00:05, 291.93it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  16% 319/2029 [00:01<00:05, 290.66it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  17% 348/2029 [00:01<00:06, 279.69it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  19% 376/2029 [00:01<00:05, 277.49it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  20% 404/2029 [00:01<00:06, 259.03it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  21% 431/2029 [00:01<00:06, 247.24it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  22% 456/2029 [00:01<00:06, 243.93it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  24% 486/2029 [00:01<00:06, 256.03it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  26% 522/2029 [00:01<00:05, 252.84it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  27% 549/2029 [00:01<00:05, 257.68it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  29% 579/2029 [00:02<00:05, 267.53it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  30% 616/2029 [00:02<00:04, 286.57it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  32% 646/2029 [00:02<00:04, 279.44it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  33% 678/2029 [00:02<00:04, 290.06it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  35% 708/2029 [00:02<00:04, 284.48it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  36% 737/2029 [00:02<00:05, 253.21it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  38% 770/2029 [00:02<00:04, 269.20it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  39% 800/2029 [00:02<00:04, 274.04it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  41% 830/2029 [00:02<00:04, 280.39it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  42% 859/2029 [00:03<00:04, 279.66it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  44% 888/2029 [00:03<00:04, 280.02it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  45% 917/2029 [00:03<00:04, 265.83it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  47% 949/2029 [00:03<00:03, 279.18it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  49% 987/2029 [00:03<00:03, 302.50it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  50% 1019/2029 [00:03<00:03, 296.98it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  52% 1050/2029 [00:03<00:03, 298.08it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  54% 1086/2029 [00:03<00:03, 314.10it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  55% 1118/2029 [00:03<00:03, 295.38it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  57% 1151/2029 [00:04<00:02, 301.22it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  58% 1184/2029 [00:04<00:02, 301.41it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  60% 1215/2029 [00:04<00:02, 295.90it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  62% 1251/2029 [00:04<00:02, 311.63it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  63% 1283/2029 [00:04<00:02, 307.48it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  65% 1315/2029 [00:04<00:02, 305.06it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  66% 1346/2029 [00:04<00:02, 304.02it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  68% 1378/2029 [00:04<00:02, 307.09it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  69% 1409/2029 [00:04<00:02, 300.03it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  71% 1442/2029 [00:04<00:01, 306.43it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  73% 1474/2029 [00:05<00:01, 309.57it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  74% 1511/2029 [00:05<00:01, 324.66it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  76% 1544/2029 [00:05<00:01, 300.35it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  78% 1575/2029 [00:05<00:01, 281.29it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  79% 1608/2029 [00:05<00:01, 293.23it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  81% 1638/2029 [00:05<00:01, 283.98it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  82% 1672/2029 [00:05<00:01, 294.54it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  84% 1702/2029 [00:05<00:01, 292.81it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  85% 1732/2029 [00:05<00:01, 288.73it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  87% 1762/2029 [00:06<00:00, 287.81it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  88% 1793/2029 [00:06<00:00, 294.04it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  90% 1832/2029 [00:06<00:00, 314.94it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  92% 1865/2029 [00:06<00:00, 311.34it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  93% 1897/2029 [00:06<00:00, 286.45it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  95% 1927/2029 [00:06<00:00, 277.37it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  96% 1956/2029 [00:06<00:00, 256.18it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  98% 1985/2029 [00:06<00:00, 263.17it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  99% 2014/2029 [00:06<00:00, 266.12it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 2029/2029 [00:07<00:00, 288.83it/s]\n",
            "trainreco= (1144,)\n",
            "len train= (34,)\n",
            "len newtrain text= (1178,)\n",
            "len newtrain label= (1178,)\n",
            "len newtrain features= (1178, 10, 24)\n",
            "len newdev features= (488, 10, 24)\n",
            "len newdev text= (488,)\n",
            "len newdev label= (488,)\n",
            "Tokenizing text: 100% 1178/1178 [00:00<00:00, 1427.50it/s]\n",
            "Preparing input matrix: 1178it [00:00, 1193.72it/s]\n",
            "Tokenizing text: 100% 488/488 [00:00<00:00, 1465.05it/s]\n",
            "Preparing input matrix: 488it [00:00, 1116.38it/s]\n",
            "Tokenizing text: 100% 406/406 [00:00<00:00, 1375.43it/s]\n",
            "Preparing input matrix: 406it [00:00, 1043.55it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_combi-MultiSourceFake-ReCOVery_10.check\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "features_input (InputLayer)  [(None, 10, 24)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 16)            1632      \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed_Layer (Embedding)         (None, 800, 300)     14171400    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 799, 16)      9616        Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 798, 16)      14416       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 797, 16)      19216       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 266, 16)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 265, 16)      0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4256)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4256)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4240)         0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12752)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,214,648\n",
            "Trainable params: 14,214,648\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 10, 800)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_sent2 (TimeDistributed)   (None, 10, 12752)    14214648    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "features_input (InputLayer)     [(None, 10, 24)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 8)        102024      input_sent2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 32)       0           features_input[0][0]             \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10, 8)        264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10, 8)        0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 10, 16)       1632        features_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Self-Attention (SeqSelfAttentio (None, 10, 8)        65          dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 16, 8)        0           bidirectional[0][0]              \n",
            "                                                                 Self-Attention[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 8)            72          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 8)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "final_softmax (Dense)           (None, 2)            18          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,318,723\n",
            "Trainable params: 14,318,723\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= train\n",
            "Epoch 1/50\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.6553WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "2022-03-13 18:02:05.618977: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "74/74 [==============================] - 177s 2s/step - loss: 0.6584 - accuracy: 0.6553 - val_loss: 0.6362 - val_accuracy: 0.6598\n",
            "Epoch 2/50\n",
            "74/74 [==============================] - 183s 2s/step - loss: 0.6056 - accuracy: 0.6698 - val_loss: 0.5496 - val_accuracy: 0.7951\n",
            "Epoch 3/50\n",
            "74/74 [==============================] - 180s 2s/step - loss: 0.3699 - accuracy: 0.8396 - val_loss: 0.3701 - val_accuracy: 0.8361\n",
            "Epoch 4/50\n",
            "74/74 [==============================] - 164s 2s/step - loss: 0.1591 - accuracy: 0.9576 - val_loss: 0.4431 - val_accuracy: 0.8545\n",
            "Epoch 5/50\n",
            "74/74 [==============================] - 165s 2s/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 0.5635 - val_accuracy: 0.8648\n",
            "Epoch 6/50\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9966\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.0000001424923538e-05.\n",
            "74/74 [==============================] - 166s 2s/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.7517 - val_accuracy: 0.8791\n",
            "Epoch 7/50\n",
            "74/74 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9983Restoring model weights from the end of the best epoch.\n",
            "74/74 [==============================] - 183s 2s/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.6982 - val_accuracy: 0.8893\n",
            "Epoch 00007: early stopping\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.56      0.68       133\n",
            "           1       0.82      0.96      0.88       273\n",
            "\n",
            "   micro avg       0.83      0.83      0.83       406\n",
            "   macro avg       0.84      0.76      0.78       406\n",
            "weighted avg       0.83      0.83      0.82       406\n",
            "\n",
            "accuracy= 0.8275862068965517\n"
          ]
        }
      ],
      "source": [
        "# combine training sets PubHealth and ReCOVery train and test on recovery\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True -batch_size 16 -epochs 10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tiqVcfABXUC",
        "outputId": "979faf15-1217-4f3c-8628-e82af232869d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-03-13 18:44:01.486847: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-13 18:44:02.957941: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-13 18:44:02.964309: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200150000 Hz\n",
            "2022-03-13 18:44:02.964579: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605ff7ea680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-13 18:44:02.964632: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-13 18:44:02.966890: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-13 18:44:02.980801: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-03-13 18:44:02.980859: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0fdb8131f36a): /proc/driver/nvidia/version does not exist\n",
            "mypath= /content/drive/MyDrive/Colab Notebooks/CS224N-NLP/cs224n_proj/fake_flow-master\n",
            "preproc= True\n",
            "Text Segmentation:   0% 0/50 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 50/50 [00:00<00:00, 491.57it/s]\n",
            "Text Segmentation:   0% 0/2029 [00:00<?, ?it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   1% 27/2029 [00:00<00:07, 262.58it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   3% 58/2029 [00:00<00:07, 274.88it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   4% 88/2029 [00:00<00:06, 281.85it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   6% 121/2029 [00:00<00:06, 294.49it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   8% 154/2029 [00:00<00:06, 296.43it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:   9% 187/2029 [00:00<00:06, 302.67it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  11% 220/2029 [00:00<00:05, 307.27it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  13% 254/2029 [00:00<00:05, 312.66it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  14% 284/2029 [00:00<00:05, 300.73it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  16% 317/2029 [00:01<00:05, 307.43it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  17% 348/2029 [00:01<00:05, 281.09it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  19% 377/2029 [00:01<00:06, 272.59it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  20% 405/2029 [00:01<00:06, 251.71it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  21% 431/2029 [00:01<00:06, 242.36it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  22% 456/2029 [00:01<00:06, 231.79it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  24% 483/2029 [00:01<00:06, 242.05it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  26% 519/2029 [00:01<00:05, 267.36it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  27% 547/2029 [00:01<00:06, 241.11it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  28% 577/2029 [00:02<00:05, 255.03it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  30% 615/2029 [00:02<00:05, 282.70it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  32% 645/2029 [00:02<00:05, 272.92it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  33% 678/2029 [00:02<00:04, 287.52it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  35% 708/2029 [00:02<00:04, 279.87it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  36% 737/2029 [00:02<00:05, 245.59it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  38% 771/2029 [00:02<00:04, 267.19it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  39% 800/2029 [00:02<00:04, 266.96it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  41% 828/2029 [00:02<00:04, 269.27it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  42% 860/2029 [00:03<00:04, 281.02it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  44% 889/2029 [00:03<00:04, 282.87it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  45% 918/2029 [00:03<00:04, 267.43it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  47% 952/2029 [00:03<00:03, 283.94it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  49% 989/2029 [00:03<00:03, 303.74it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  50% 1021/2029 [00:03<00:03, 299.29it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  52% 1052/2029 [00:03<00:03, 298.01it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  54% 1087/2029 [00:03<00:03, 311.38it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  55% 1119/2029 [00:03<00:03, 302.63it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  57% 1152/2029 [00:04<00:02, 309.16it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  58% 1184/2029 [00:04<00:02, 311.33it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  60% 1216/2029 [00:04<00:02, 300.64it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  62% 1253/2029 [00:04<00:02, 316.53it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  63% 1286/2029 [00:04<00:02, 308.84it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  65% 1318/2029 [00:04<00:02, 304.38it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  66% 1349/2029 [00:04<00:02, 298.79it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  68% 1382/2029 [00:04<00:02, 303.76it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  70% 1413/2029 [00:04<00:02, 298.73it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  71% 1446/2029 [00:05<00:01, 306.34it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  73% 1483/2029 [00:05<00:01, 322.52it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  75% 1516/2029 [00:05<00:01, 307.20it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  76% 1548/2029 [00:05<00:01, 301.39it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  78% 1579/2029 [00:05<00:01, 281.26it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  79% 1611/2029 [00:05<00:01, 291.72it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  81% 1641/2029 [00:05<00:01, 275.65it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  83% 1674/2029 [00:05<00:01, 288.76it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  84% 1704/2029 [00:05<00:01, 287.47it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  85% 1734/2029 [00:06<00:01, 270.99it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  87% 1773/2029 [00:06<00:00, 293.87it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  89% 1805/2029 [00:06<00:00, 300.31it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  90% 1836/2029 [00:06<00:00, 295.83it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  92% 1873/2029 [00:06<00:00, 311.12it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  94% 1905/2029 [00:06<00:00, 289.06it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  95% 1935/2029 [00:06<00:00, 273.40it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  97% 1963/2029 [00:06<00:00, 252.90it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation:  98% 1992/2029 [00:06<00:00, 261.12it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 2024/2029 [00:07<00:00, 276.24it/s]New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "New Preprocessing added\n",
            "Text Segmentation: 100% 2029/2029 [00:07<00:00, 287.67it/s]\n",
            "trainreco= (1144,)\n",
            "len train= (34,)\n",
            "len newtrain text= (1178,)\n",
            "len newtrain label= (1178,)\n",
            "len newtrain features= (1178, 10, 24)\n",
            "len newdev features= (488, 10, 24)\n",
            "len newdev text= (488,)\n",
            "len newdev label= (488,)\n",
            "Tokenizing text: 100% 1178/1178 [00:00<00:00, 1449.80it/s]\n",
            "Preparing input matrix: 1178it [00:00, 1191.12it/s]\n",
            "Tokenizing text: 100% 488/488 [00:00<00:00, 1369.06it/s]\n",
            "Preparing input matrix: 488it [00:00, 1147.42it/s]\n",
            "Tokenizing text: 100% 406/406 [00:00<00:00, 1364.78it/s]\n",
            "Preparing input matrix: 406it [00:00, 1073.94it/s]\n",
            "file= ./processed_files/saved_models/fake_flow_combi-MultiSourceFake-ReCOVery_10.check\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "features_input (InputLayer)  [(None, 10, 24)]          0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 10, 16)            1632      \n",
            "=================================================================\n",
            "Total params: 1,632\n",
            "Trainable params: 1,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embed_Layer (Embedding)         (None, 800, 300)     14171400    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 799, 16)      9616        Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 798, 16)      14416       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 797, 16)      19216       Embed_Layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 266, 16)      0           conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 266, 16)      0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling1d (AveragePooli (None, 265, 16)      0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 4256)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 4256)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 4240)         0           average_pooling1d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12752)        0           flatten[0][0]                    \n",
            "                                                                 flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,214,648\n",
            "Trainable params: 14,214,648\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"functional_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 10, 800)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_sent2 (TimeDistributed)   (None, 10, 12752)    14214648    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "features_input (InputLayer)     [(None, 10, 24)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10, 8)        102024      input_sent2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 32)       0           features_input[0][0]             \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10, 8)        264         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 10, 8)        0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 10, 16)       1632        features_input[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Self-Attention (SeqSelfAttentio (None, 10, 8)        65          dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 16, 8)        0           bidirectional[0][0]              \n",
            "                                                                 Self-Attention[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8)            0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 8)            72          lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 8)            0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "final_softmax (Dense)           (None, 2)            18          dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 14,318,723\n",
            "Trainable params: 14,318,723\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "type= test\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.56      0.68       133\n",
            "           1       0.82      0.96      0.88       273\n",
            "\n",
            "   micro avg       0.83      0.83      0.83       406\n",
            "   macro avg       0.84      0.76      0.78       406\n",
            "weighted avg       0.83      0.83      0.82       406\n",
            "\n",
            "accuracy= 0.8275862068965517\n",
            "--------Load Weights Successful!--------\n",
            "report results=               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.56      0.68       133\n",
            "           1       0.82      0.96      0.88       273\n",
            "\n",
            "   micro avg       0.83      0.83      0.83       406\n",
            "   macro avg       0.84      0.76      0.78       406\n",
            "weighted avg       0.83      0.83      0.82       406\n",
            "\n",
            "accuracy= 0.8275862068965517\n"
          ]
        }
      ],
      "source": [
        "# load saved model\n",
        "# combine training sets PubHealth and ReCOVery train=testing\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m test -c True -batch_size 16 -epochs 10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V4JiDAYBu22"
      },
      "outputs": [],
      "source": [
        "#search params for previous experiment\n",
        "# !python fake_flow.py -d PubHealth -otherd ReCOVery -sn 10 -m train -c True -s 60 -batch_size 16 -epochs 10 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drt___uVByVk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDTaprcRf3ie"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO1F1AJhhLPc"
      },
      "source": [
        "## Explore some predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AK-Bwl8IYKaE",
        "outputId": "6d556018-98e8-41fe-d739-b0fa18951b43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              content  label  predictions\n",
              "0   please make babies fans go into overdrive as t...      1            1\n",
              "1   blake shelton and lindsey sporrer cheating on ...      0            1\n",
              "2   ellen degeneres sends her producer to another ...      1            1\n",
              "3   jennifer aniston's spokesman denies reports th...      1            1\n",
              "4   queen bey beyonce gets taylor swift banned fro...      0            1\n",
              "..                                                ...    ...          ...\n",
              "95  kendall and kylie spent father's day with cait...      1            1\n",
              "96  selena gomez and the weeknd hold hands for a r...      1            1\n",
              "97  halle berry jokes about pregnancy rumors updat...      1            1\n",
              "98  tyga to reveal the ugly truth about kylie jenn...      0            1\n",
              "99  hats off to love jennifer lawrence and darren ...      1            1\n",
              "\n",
              "[100 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95d5ac68-fed9-4b05-85d1-b95ff4c0c23a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>please make babies fans go into overdrive as t...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blake shelton and lindsey sporrer cheating on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ellen degeneres sends her producer to another ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jennifer aniston's spokesman denies reports th...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>queen bey beyonce gets taylor swift banned fro...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>kendall and kylie spent father's day with cait...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>selena gomez and the weeknd hold hands for a r...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>halle berry jokes about pregnancy rumors updat...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>tyga to reveal the ugly truth about kylie jenn...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>hats off to love jennifer lawrence and darren ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95d5ac68-fed9-4b05-85d1-b95ff4c0c23a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95d5ac68-fed9-4b05-85d1-b95ff4c0c23a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95d5ac68-fed9-4b05-85d1-b95ff4c0c23a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "# see predicted results for analysis\n",
        "\n",
        "predicted_table = pd.read_csv(\"./processed_files/predictions_fake_flow_combi-newtestMultiSourceFake-ReCOVery_10.csv\")\n",
        "\n",
        "\n",
        "predicted_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI66b6WgTaqG"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ecCPrptgYkUD",
        "outputId": "4adfd48d-b341-42c2-d341-62bdf277085f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "len= 5617\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dc664e95-52d5-46da-990b-2f5b51c1e436\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how nasa is preparing to launch humans to spac...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>an adoption a pandemic and an evacuation the l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>state and federal data on covid testing don't ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>premier league suspends season indefinitelylon...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>two cats are first uspets to test positive for...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>piers morgan bans all cabinet ministers from t...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>when and where you can see navy blue angels an...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>in covid britain it pays to run your washing m...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>common urges jail releases amid pandemic with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>over percent of tested inmates in federal pris...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc664e95-52d5-46da-990b-2f5b51c1e436')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc664e95-52d5-46da-990b-2f5b51c1e436 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc664e95-52d5-46da-990b-2f5b51c1e436');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              content  label  predictions\n",
              "0   how nasa is preparing to launch humans to spac...      1            1\n",
              "1   an adoption a pandemic and an evacuation the l...      1            1\n",
              "2   state and federal data on covid testing don't ...      1            1\n",
              "3   premier league suspends season indefinitelylon...      1            1\n",
              "4   two cats are first uspets to test positive for...      1            1\n",
              "5   piers morgan bans all cabinet ministers from t...      0            0\n",
              "8   when and where you can see navy blue angels an...      1            1\n",
              "9   in covid britain it pays to run your washing m...      1            1\n",
              "13  common urges jail releases amid pandemic with ...      1            1\n",
              "14  over percent of tested inmates in federal pris...      1            1"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('len=',len(predicted_table[\"content\"][0]))\n",
        "\n",
        "filtered_true = predicted_table[predicted_table[\"label\"]==(predicted_table[\"predictions\"]&1)]\n",
        "# filtered[\"content\"][0]\n",
        "filtered_true.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "kJSUN2Rra5fT",
        "outputId": "456f31e1-4a5e-4252-f99c-e47bd5858cb2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"how nasa is preparing to launch humans to space as coronavirus pandemic worsensas the coronavirus pandemic continues to worsen in the us nasa is still moving forward with many of its upcoming missions including some launches that will send humans to the international space station in the near future as of now nasa does not foresee any changes being made to these missions and there are already procedures in place to guarantee astronauts do not bring any illnesses with them into space nasa has its own internal response framework for how it plans to . deal with the pandemic it lists four different stages for the agency which each detail the amount of people who will work from home the level of access to nasa facilities and how much travel will be allowed right now two nasa centers ames research center and marshall space flight center are on stage which makes telework mandatory and only allows mission essential personnel on site at facilities nasa bumped these two centers to stage after employees tested positive for covid at each place nasa has its own internal response framework for how to . deal with the pandemic nasa's johnson space center which oversees the agency's human spaceflight launches and operates the international space station is only at stage at that level teleworking is strongly encouraged though not mandatory while various facilities are closed down the health and safety of nasa's workforce is the agency's top priority as the coronavirus covid concern continues to escalate nasa is taking steps to ensure its workforce is protected and informed a nasa spokesperson at jsc said in a statement but as more workers at jsc stay home they're still looking ahead . to the next launch of people to the iss which is slated for april th out of kazakhstan a russian soyuz rocket will launch three crew members including nasa astronaut chris cassidy to the station where they'll join three people already in orbit that launch is still on and nasa says the agency hasn't made any changes to operations and schedule surrounding the mission as of yesterday kazakhstan effectively closed its borders after reporting its first coronavirus cases in the country no one can enter the country except for diplomats returning citizens and those . invited by the country's government according to reuters nasa is still assessing if changes are needed regarding how personnel will travel to kazakhstan of course the concern is that the astronauts flying to the station could carry the coronavirus with them if they don't know that they're infected with the virus but nasa already has a long held strategy in place for preventing astronauts from carrying any nasty bugs with them to space all astronauts going to orbit must go through a two week period of quarantine called health stabilization according to nasa that . way the agency can make sure the crew is not incubating any illnesses before launch however nasa said it will continue to evaluate and augment this plan in coordination with its international and commercial partners if needed in the meantime russia's state space corporation roscosmos has decided to shut down all media activity surrounding the soyuz launch barring journalists from covering the mission in person russia will still live stream the launch and nasa typically airs all of its crewed launches on its own online tv channel all astronauts going to orbit must go . through a two week period of quarantine once this launch is over the next big milestone for jsc is the return of crew from the iss nasa astronauts andrew morgan jessica meir and russian cosmonaut oleg skripochka are slated to return to earth in a soyuz capsule in mid april landing in the kazakhstan desert such landings typically require large groups of recovery personnel to extract the astronauts from the landed capsule nasa did not provide any details if those operations would change in light of the pandemic however nasa has more than one . upcoming crewed mission on its calendar soon nasa's commercial partner spacex will be ready to send its first crew of nasa astronauts to the international space station the launch is a critical one for nasa's commercial crew program an initiative to develop privately funded vehicles to transport people to and from the iss spacex has been developing its crew dragon capsule for the program and the first vehicle that will fly a crew of two to the station is already in florida ahead of its inaugural flight spacex is currently targeting may for . that flight according to the company's president gwynne shotwell nasa also says that spacex's passengers for the mission astronauts bob behnken and doug hurley are continuing to train for the mission as originally planned as for operations at spacex it seems like things are still moving ahead as usual spacex ceo elon musk sent an email last week to the company's employees underplaying the coronavirus threat arguing people were more likely to die in a car crash than from the virus of course the situations at nasa and spacex are subject to change . quickly the coronavirus pandemic is ever evolving with cities states and countries making swift changes every few hours to combat the spread of the disease and already launches are being affected europe's primary spaceport in french guiana south america is suspending all launches from the site for the foreseeable future in order to protect the health of employees and people in the area it's possible that upcoming launches from the us could be postponed as well it just depends on how companies plan to react and if governments take even more decisive action\""
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hpSnB_SrYpdj",
        "outputId": "70b4b98d-c58f-4eec-fedc-cd6b322612e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88fecef2-d326-4576-a58f-d6b771d0f2c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>class warfare will worsen the pandemicmedieval...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>california illegal alien giveaway helpline get...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>updated daily deaths so far and countingdate c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>in honor of the class of some scalding coffeei...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>coronavirus pandemic to change the world unrec...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88fecef2-d326-4576-a58f-d6b771d0f2c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88fecef2-d326-4576-a58f-d6b771d0f2c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88fecef2-d326-4576-a58f-d6b771d0f2c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              content  label  predictions\n",
              "6   class warfare will worsen the pandemicmedieval...      0            1\n",
              "7   california illegal alien giveaway helpline get...      0            1\n",
              "10  updated daily deaths so far and countingdate c...      0            1\n",
              "11  in honor of the class of some scalding coffeei...      0            1\n",
              "12  coronavirus pandemic to change the world unrec...      0            1"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_false0 = predicted_table[(predicted_table[\"label\"]==0)&(predicted_table[\"predictions\"]==1)]\n",
        "# filtered[\"content\"][0]\n",
        "filtered_false0.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "b3Gcdl0ZbENF",
        "outputId": "066842ad-41fe-4954-c8e5-7e741ad24aa0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"blake shelton and lindsey sporrer cheating on miranda lambert divorce expected celeb dirty laundry it looks like miranda lambert's absolute worst fear may be coming true judging from recent photos . blake shelton may really have found himself a younger skinnier version of his standoffish wife blake decided to attend usher's th birthday party and miranda was nowhere to be found . it's almost like she goes out of her way to avoid blake when he is around anyone that he works with and then throws it in his face that they're . always apart anyway on this particular night she was at home but don't think for a minute that blake was lonely according to radar online blake posed for photos with . lindsey sporrer and the two were connected at the shoulder all night you know how blake is get him drinking and fidelity goes right out the window miranda is no . doubt losing her mind over this because let's be serious here this chick poses a real threat miranda knows the drill well because she was once the younger thinner chick . that disrupted blake's first marriage she knows exactly how her husband operates and she also has to realize that lindsey is exactly his type do you think that this is . the beginning or real trouble for these two i mean we have heard for months that they are on shaky ground but they have then presented a united front . is lindsey going to be the last straw for miranda will she continue to deny her husband's bad behavior by sharing all of the ways that she double checks . and keeps tabs on him i think they are going to crash and burn sooner rather than later how about you tell us your thoughts in the comments below\""
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1sawiCvIauW_",
        "outputId": "f4e20061-e7ba-4e2b-f65e-da973d3e8a3d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88e3ffef-3c04-45a0-9fe2-bac913674905\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>selena gomez thinks justin bieber's soft lips ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>blake shelton and lindsey sporrer cheating on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>digital diva inside caitlyn jenner's secret cy...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is jared leto crushing on year old paris jacks...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>kendall kylie who caitlyn jenner jump starts a...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88e3ffef-3c04-45a0-9fe2-bac913674905')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88e3ffef-3c04-45a0-9fe2-bac913674905 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88e3ffef-3c04-45a0-9fe2-bac913674905');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             content  label  predictions\n",
              "2  selena gomez thinks justin bieber's soft lips ...      0            1\n",
              "5  blake shelton and lindsey sporrer cheating on ...      0            1\n",
              "6  digital diva inside caitlyn jenner's secret cy...      0            1\n",
              "7  is jared leto crushing on year old paris jacks...      0            1\n",
              "8  kendall kylie who caitlyn jenner jump starts a...      0            1"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_false1 = predicted_table[predicted_table[\"label\"]!=(predicted_table[\"predictions\"]&1)]\n",
        "# filtered[\"content\"][0]\n",
        "filtered_false1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "jw_RYQkPa0g9",
        "outputId": "2f00939b-de6b-49de-d7d4-a11b74a42c72"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"kim kardashian opens up to about life after the paris robbery this morning kim kardashian west is a few minutes late to breakfast because she can't get this gel mask thing off her face she's staying in a room in the upper reaches of the baccarat hotel in midtown manhattan a room with a giant bed in it in which she slept butt to butt with her four year old daughter north and in that room she applied a mask of the cosmetic variety not the halloween variety only to discover she couldn't really get it off where did she get this gold gel mask thing that's supposed to make your skin healthier man when you're kim kardashian west you don't know where everything comes from people just give you stuff the vaults and doors and express delivery accounts of the world open and a free flow of stuff just washes over you . kim tries to enjoy it because that's the enlightened thing to do but right now she's upstairs in her room trying to separate her face from the free gel mask thing it is a m i wait for her in the sumptuous lobby baccarat for those who do not shop for vases is a french company that makes crystal and being inside the baccarat hotel is like being inside a fine crystal lamp where an urbane french genie who wears louis vuitton suits lives here's the kind of place it is from le menu du petit d jeuner at the petit salon in the hotel gets you two eggs potatoes bacon juice and coffee there is an actual crown on display on a shelf full of curios and crystals unless it's the world's most bejeweled serving dome but kim kdoes not make me wait too long seven minutes after she arrives she looks . somehow naked her face anyway it is scrubbed clean i guess from the mask removal there is a stunning absence of makeup except for some lip balm that she tells me she got in iceland which is ironic given that the year old recently launched her own makeup line it's called kkw beauty predictably she has utterly crushed the stuff for your face market the way she has crushed all other markets i think part of the reason her facial nudity is so striking is that being simple and unadorned isn't really her role her role is more queen of america married to the king of hip hop fashion intellectual provocation and possible public insanity performance art queen of instagram queen of a certain type of television queen of relevance the queen of calabasas california which if you don't know is the mount olympus of our time will smith lives there and justin . bieber and drake and the rock and the osbournes and if you think about who's the queen of those people wouldn't you say kim kardashian west i know you're probably wondering what she was wearing you're probably saying to yourself what did she eat for breakfast i'm not going to make you wait for it she wears this cool rocky balboa retro gray cotton hoodie with the american olympic team logo on it and gray sweatpants and she orders scrambled eggs with tomatoes mushrooms and onions mixed in an english muffin and some english breakfast tea with loads of honey did she eat everything don't be afraid to wonder if you don't care whether kim kardashian west ate her english muffin you need to go back to kim kardashian west school so you can appreciate the wonderful granular gossipyness that's part of what's so enjoyable about knowing everything about kim kbefore you come . back here with your too good to want to know if she eats her english muffin ness i'm like the most fit i've ever been she says how do you get in shape if you're kim kthe same way you do everything instagram you go and you find this bodybuilder on instagram and you contact her you find someone who as kim ktells it had an amazing transformation after she had a baby and kim khappened to be in the market for a really amazing transformation after giving birth now kim's working out an hour and a half a day kim kardashian west i don't want to scandalize you has had her picture taken nearly naked before for playboy and completely nude for paper gq and w magazines and that doesn't even include the original document of her fame the storied ray j sex tape my publicist would say to me you're not . getting naked i have to be there she says i suggest that if your publicist keeps warning you not to get naked she must know you're always in danger of getting naked is there an age limit for the naked photo shoot yes she says i'm like i'm going to tone it down but then i'm like wait i can't be doing it in years so i might as well i don't know what the age cutoff is we know everything about kim kardashian west she has shown us everything talked about everything many times in different languages kim has talked about basketball and baby poop and having no idea where pickles come from and the texture of cardboard and kanye and caitlyn jenner and her sister's boyfriend's drug problems recently on her show we even watched her share the story of how difficult her pregnancy and birthing process was and how she's . looking at some alternatives to carrying her next kid herself have you ever considered besides the solipsism the bravery in that you know the unflinching way she takes off her top in front of a camera or wears a billion dress that's how unflinchingly she talks about the fragility of her own human body it's feminist it's a psa here in this glass enclosed beveled luxury maze while wealthy french businessmen finish eating their toast i ask if she's thought about a third child and she retains this unblinking steady state feline eye contact and a sense of self assurance that could freeze water while she says i would like to but i've had lots and lots of complications i had preeclampsia and then i also had something called placenta accreta we've explored surrogacy we're thinking about it i get the vibe from her that just as she has the crushing instincts . necessary to lay waste to our culture and create an america in her image or is it that she's created america's image she also has the instinct to preserve the humanity of her family we don't do gifts she says when i ask her if she worries about her kids growing up with too much kanye and i talk about it all the time about not getting too much and trying to be as grounded and well rounded as possible she holds herself to the same standard i don't like presents anymore she says we just did absolutely nothing for our anniversary we spent two days in santa barbara and we slept then she remembers you know what i think we went to ihop that's what we did and then she tells me this story a motherhood story it's about the time last year in paris when she was held at gunpoint . and bound and robbed in a hotel by masked gunmen well she tells me she'd been scared to go on that trip she was afraid of a terrorist attack she'd never experienced anxiety like that before she even went to a therapist about it and north sensing her mother's anxiety wanted to reassure her she gave me a little plastic treasure box and she put her little jewels in it like fake little plastic jewels and she was like mommy this will keep you safe when you go to paris it is something that despite all the jewels and calabasas houses and red carpet gowns and original basquiats and rolls royces and pairs of yeezy boots she has penetrates down into the depths of kim kardashian west's humanity which at least after spending a few hours with her i believe is very much there to have something really sweet like that is . more important to me than all the jewelry she says she tells me she takes it everywhere with her around us european businessmen sign their checks step into hushed elevators and are whisked to meetings with continental vampires kim ksays she's going to see what north is up to i'm trying to figure out what's weird about seeing her in person at this phase of her life and i think it's that she wears her crown lightly i guess it's that she's chill which doesn't seem like the one word you'd use for kim ki guess it's that she's really a mom now she is a beautiful worldly year old woman drinking the last of a cup of english breakfast tea before going out into the world to see to her empire with her four year old child at her side bearing witness to the domination but never expecting you know presents\""
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lrdPEXUa0jw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeI9nNYLN01e"
      },
      "source": [
        "# Import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-cqGUqFN3uI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "import os, random, gensim\n",
        "from gensim import models\n",
        "from os.path import exists, join\n",
        "import string\n",
        "import json\n",
        "import shutil\n",
        "from string import punctuation, digits\n",
        "import re\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM, GRU, Embedding, Input, Dropout, Bidirectional, MaxPooling1D, Convolution1D, \\\n",
        "    Flatten, Concatenate, concatenate, TimeDistributed,Bidirectional\n",
        "from keras.preprocessing import text,sequence \n",
        "from tensorflow.keras import regularizers\n",
        "# from keras.layers.embeddings import Embedding\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report,f1_score,accuracy_score,confusion_matrix,precision_score,recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ3KiRdr_dGJ",
        "outputId": "7c028ee2-e6a1-4153-b3d9-768867bcced5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "# from nltk import tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words = stopwords.words(\"english\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lFEZjtaiAXd"
      },
      "outputs": [],
      "source": [
        "#  use gpu\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcfVKvgE5dLN"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAn5l58YR0QG"
      },
      "source": [
        "## Recovery \n",
        "True with 1 and fake with 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "c1akbBntRtqY",
        "outputId": "3ee81bc6-6e5e-45ea-b21d-1ccb9f256f38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape= (2029, 13)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0a5389ec-bc52-4fbe-8e2c-61b9a76e614a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>news_id</th>\n",
              "      <th>url</th>\n",
              "      <th>publisher</th>\n",
              "      <th>publish_date</th>\n",
              "      <th>author</th>\n",
              "      <th>title</th>\n",
              "      <th>image</th>\n",
              "      <th>body_text</th>\n",
              "      <th>political_bias</th>\n",
              "      <th>country</th>\n",
              "      <th>reliability</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>814</td>\n",
              "      <td>814</td>\n",
              "      <td>https://chicago.suntimes.com/city-hall/2020/5/...</td>\n",
              "      <td>Chicago Sun-Times</td>\n",
              "      <td>2020-05-12</td>\n",
              "      <td>['Fran Spielman']</td>\n",
              "      <td>Lightfoot exploring more ways to prevent mayor...</td>\n",
              "      <td>https://cdn.vox-cdn.com/thumbor/VAU-w1zq5tTilp...</td>\n",
              "      <td>Mayor Lori Lightfoot said Tuesday her top aide...</td>\n",
              "      <td>Left-center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>535</td>\n",
              "      <td>535</td>\n",
              "      <td>https://www.businessinsider.com/coronavirus-he...</td>\n",
              "      <td>Business Insider</td>\n",
              "      <td>2020-04-30</td>\n",
              "      <td>['Anthony L. Fisher']</td>\n",
              "      <td>Coronavirus hero Cuomo helped create New York'...</td>\n",
              "      <td>https://i.insider.com/5ea9c4843dac9a008731f97e...</td>\n",
              "      <td>Compared with the Mayor Bill de Blasio of New ...</td>\n",
              "      <td>Left-center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1383</td>\n",
              "      <td>1383</td>\n",
              "      <td>https://amgreatness.com/2020/05/19/we-were-nev...</td>\n",
              "      <td>Heartland Institute</td>\n",
              "      <td>2020-05-19</td>\n",
              "      <td>['Christopher Roach']</td>\n",
              "      <td>We Were Never Asked</td>\n",
              "      <td>https://overland.amgreatness.com/app/uploads/2...</td>\n",
              "      <td>Common sense and the interests of the common p...</td>\n",
              "      <td>Extreme right</td>\n",
              "      <td>USA</td>\n",
              "      <td>0</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>493</td>\n",
              "      <td>493</td>\n",
              "      <td>https://www.theverge.com/2020/4/29/21241845/fa...</td>\n",
              "      <td>The Verge</td>\n",
              "      <td>2020-04-29</td>\n",
              "      <td>['Nick Statt']</td>\n",
              "      <td>Facebook usage is surging, but the company war...</td>\n",
              "      <td>https://cdn.vox-cdn.com/thumbor/KXAhazZGGRE0A7...</td>\n",
              "      <td>Facebook’s business is booming, thanks to worl...</td>\n",
              "      <td>Left-center</td>\n",
              "      <td>USA</td>\n",
              "      <td>1</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1437</td>\n",
              "      <td>1437</td>\n",
              "      <td>http://uk.reuters.com/article/uk-health-corona...</td>\n",
              "      <td>Reuters</td>\n",
              "      <td>2020-05-19</td>\n",
              "      <td>[]</td>\n",
              "      <td>UK says 14 billion pounds approved so far in 1...</td>\n",
              "      <td>https://s3.reutersmedia.net/resources/r/?m=02&amp;...</td>\n",
              "      <td>FILE PHOTO: Britain's Chancellor of the Excheq...</td>\n",
              "      <td>Center</td>\n",
              "      <td>UK</td>\n",
              "      <td>1</td>\n",
              "      <td>training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a5389ec-bc52-4fbe-8e2c-61b9a76e614a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a5389ec-bc52-4fbe-8e2c-61b9a76e614a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a5389ec-bc52-4fbe-8e2c-61b9a76e614a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  news_id                                                url  \\\n",
              "0         814      814  https://chicago.suntimes.com/city-hall/2020/5/...   \n",
              "1         535      535  https://www.businessinsider.com/coronavirus-he...   \n",
              "2        1383     1383  https://amgreatness.com/2020/05/19/we-were-nev...   \n",
              "3         493      493  https://www.theverge.com/2020/4/29/21241845/fa...   \n",
              "4        1437     1437  http://uk.reuters.com/article/uk-health-corona...   \n",
              "\n",
              "             publisher publish_date                 author  \\\n",
              "0    Chicago Sun-Times   2020-05-12      ['Fran Spielman']   \n",
              "1     Business Insider   2020-04-30  ['Anthony L. Fisher']   \n",
              "2  Heartland Institute   2020-05-19  ['Christopher Roach']   \n",
              "3            The Verge   2020-04-29         ['Nick Statt']   \n",
              "4              Reuters   2020-05-19                     []   \n",
              "\n",
              "                                               title  \\\n",
              "0  Lightfoot exploring more ways to prevent mayor...   \n",
              "1  Coronavirus hero Cuomo helped create New York'...   \n",
              "2                                We Were Never Asked   \n",
              "3  Facebook usage is surging, but the company war...   \n",
              "4  UK says 14 billion pounds approved so far in 1...   \n",
              "\n",
              "                                               image  \\\n",
              "0  https://cdn.vox-cdn.com/thumbor/VAU-w1zq5tTilp...   \n",
              "1  https://i.insider.com/5ea9c4843dac9a008731f97e...   \n",
              "2  https://overland.amgreatness.com/app/uploads/2...   \n",
              "3  https://cdn.vox-cdn.com/thumbor/KXAhazZGGRE0A7...   \n",
              "4  https://s3.reutersmedia.net/resources/r/?m=02&...   \n",
              "\n",
              "                                           body_text political_bias country  \\\n",
              "0  Mayor Lori Lightfoot said Tuesday her top aide...    Left-center     USA   \n",
              "1  Compared with the Mayor Bill de Blasio of New ...    Left-center     USA   \n",
              "2  Common sense and the interests of the common p...  Extreme right     USA   \n",
              "3  Facebook’s business is booming, thanks to worl...    Left-center     USA   \n",
              "4  FILE PHOTO: Britain's Chancellor of the Excheq...         Center      UK   \n",
              "\n",
              "   reliability      type  \n",
              "0            1  training  \n",
              "1            1  training  \n",
              "2            0  training  \n",
              "3            1      test  \n",
              "4            1  training  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Path to datasets in csv\n",
        "recopath= FOLDERNAME+'/data/ReCOVery/dataset'\n",
        "\n",
        "# tabrecovery = pd.read_csv(recopath+\"/recovery-news-data.csv\")\n",
        "tabrecovery = pd.read_csv(recopath+\"/ReCOVery.csv\")\n",
        "print(\"shape=\",tabrecovery.shape)\n",
        "tabrecovery.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SQ98QAU98Aw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "BBjwfSPZbXz_",
        "outputId": "dc15fc5f-b3e7-4d36-d24b-b5076b5bc5a4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sns.countplot(x='label', data=tabrecovery)\n",
        "plt.title(\"Number of Fake and Genuine News in ReCOVery dataset\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBUHt29O8z0j"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-ORwYQv_DgZ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iUhXyVjIjwnl"
      ],
      "name": "Fakeflow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}